#!/usr/bin/env bash
#
# speed — SPEED orchestration CLI for autonomous product development
#
# Usage: ./speed/speed <command> [options]
#
# Commands:
#   init                    Initialize project for SPEED development
#   validate <specs-dir>    Cross-validate all specs for consistency
#   plan <spec-file> [opts] Decompose a spec into a task DAG + contract
#   verify                  Blind-verify the plan against the product spec
#   run [options]           Execute pending tasks with parallel agents
#   status                  Show SPEED state and progress
#   coherence               Check cross-task consistency before integration
#   integrate               Merge completed branches into main
#   review [--task-id ID]   Run code review on completed tasks
#   fix-nits [--task-id ID] Create a task to fix reviewer nits
#   retry --task-id ID      Retry a failed task with human guidance
#   recover                 Recover from crashed/stale state
#   guardian [spec-file]     Run Product Guardian vision check
#   help                    Show this help message

set -euo pipefail

# ── Bootstrap ────────────────────────────────────────────────────
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

source "${SCRIPT_DIR}/lib/config.sh"
source "${SCRIPT_DIR}/lib/log.sh"
source "${SCRIPT_DIR}/lib/cleanup.sh"
source "${SCRIPT_DIR}/lib/progress.sh"
source "${SCRIPT_DIR}/lib/git.sh"
source "${SCRIPT_DIR}/lib/provider.sh"
source "${SCRIPT_DIR}/lib/tasks.sh"
source "${SCRIPT_DIR}/lib/grounding.sh"
source "${SCRIPT_DIR}/lib/gates.sh"
source "${SCRIPT_DIR}/lib/lock.sh"
source "${SCRIPT_DIR}/lib/features.sh"

# ── Cleanup trap ─────────────────────────────────────────────
# Kill orphaned agent processes and remove temp files on exit/interrupt.
trap cleanup_all EXIT INT TERM

# ── Helpers ──────────────────────────────────────────────────────

speed_help() {
    echo ""
    echo -e "${BOLD}speed${RESET} — SPEED orchestration for autonomous product development"
    echo ""
    echo -e "${BOLD}USAGE${RESET}"
    echo "    ./speed/speed <command> [options]"
    echo ""
    echo -e "${BOLD}WORKFLOW${RESET}"
    echo -e "    ${COLOR_DIM}1.${RESET} ${COLOR_STEP}init${RESET}       → ${COLOR_DIM}Initialize project${RESET}"
    echo -e "    ${COLOR_DIM}2.${RESET} ${COLOR_STEP}validate${RESET}   → ${COLOR_DIM}Cross-validate specs${RESET}"
    echo -e "    ${COLOR_DIM}3.${RESET} ${COLOR_STEP}plan${RESET}       → ${COLOR_DIM}Guardian gate → Decompose spec into task DAG + contract${RESET}"
    echo -e "    ${COLOR_DIM}4.${RESET} ${COLOR_STEP}verify${RESET}     → ${COLOR_DIM}Blind-check plan against spec${RESET}"
    echo -e "    ${COLOR_DIM}5.${RESET} ${COLOR_STEP}run${RESET}        → ${COLOR_DIM}Execute tasks with parallel agents${RESET}"
    echo -e "    ${COLOR_DIM}6.${RESET} ${COLOR_STEP}review${RESET}     → ${COLOR_DIM}Code review + Guardian gate on completed tasks${RESET}"
    echo -e "    ${COLOR_DIM}7.${RESET} ${COLOR_STEP}coherence${RESET}  → ${COLOR_DIM}Cross-task consistency check${RESET}"
    echo -e "    ${COLOR_DIM}8.${RESET} ${COLOR_STEP}integrate${RESET}  → ${COLOR_DIM}Merge + regression + contract + Guardian gate${RESET}"
    echo ""
    echo -e "${BOLD}COMMANDS${RESET}"
    echo -e "    ${COLOR_STEP}init${RESET}                        Initialize project for SPEED development"
    echo -e "    ${COLOR_STEP}validate${RESET} <specs-dir>         Cross-validate all specs for consistency"
    echo -e "    ${COLOR_STEP}plan${RESET} <spec-file> [opts]      Decompose a product spec into task DAG + contract"
    echo -e "    ${COLOR_STEP}verify${RESET}                       Blind-verify plan against product spec"
    echo -e "    ${COLOR_STEP}run${RESET}  [options]               Execute pending tasks with parallel agents"
    echo -e "    ${COLOR_STEP}status${RESET}                       Show SPEED state and progress"
    echo -e "    ${COLOR_STEP}coherence${RESET}                    Cross-task consistency check pre-integration"
    echo -e "    ${COLOR_STEP}integrate${RESET}                    Merge completed branches + regression + contract"
    echo -e "    ${COLOR_STEP}review${RESET} [--task-id ID]        Run code review on completed tasks"
    echo -e "    ${COLOR_STEP}fix-nits${RESET} [--task-id ID]      Create a task to fix reviewer nits"
    echo -e "    ${COLOR_STEP}retry${RESET}  --task-id ID --context Retry a failed task with human guidance"
    echo -e "    ${COLOR_STEP}recover${RESET}                      Recover from crashed/stale SPEED state"
    echo -e "    ${COLOR_STEP}clean${RESET}   [logs|all]            Remove logs or entire .speed/ state"
    echo -e "    ${COLOR_STEP}guardian${RESET} [spec-file]           Run Product Guardian vision check"
    echo -e "    ${COLOR_STEP}new${RESET} <type> <name>           Scaffold a new spec from template"
    echo -e "    ${COLOR_STEP}gates${RESET}   --task ID             Run quality gates for a task (used by Developer Agent mid-task)"
    echo -e "    ${COLOR_STEP}help${RESET}                         Show this help message"
    echo ""
    echo -e "${BOLD}GLOBAL OPTIONS${RESET}"
    echo -e "    --feature NAME              Target a specific feature (auto-detected if omitted)"
    echo -e "    --quiet                     Errors and final result only"
    echo -e "    --verbose                   Show extra detail (gate output, agent commands)"
    echo -e "    --debug                     Show internal state, timing, PID tracking"
    echo -e "    --json                      Output structured JSON to stdout (logs to stderr)"
    echo ""
    echo -e "${BOLD}PLAN OPTIONS${RESET}"
    echo -e "    --specs-dir DIR             Directory with related specs for cross-referencing"
    echo ""
    echo -e "${BOLD}RUN OPTIONS${RESET}"
    echo -e "    --max-parallel N            Max concurrent agents (default: ${DEFAULT_MAX_PARALLEL})"
    echo -e "    --model MODEL               Developer model: sonnet|opus|haiku (default: ${MODEL_SUPPORT})"
    echo ""
    echo -e "${BOLD}INTEGRATE OPTIONS${RESET}"
    echo -e "    --skip-tests                Skip post-integration regression tests"
    echo ""
    echo -e "${BOLD}RETRY OPTIONS${RESET}"
    echo -e "    --task-id ID                Target a specific failed task (required)"
    echo -e "    --context \"...\"             Human guidance for the retry (required)"
    echo -e "    --escalate                  Upgrade model on retry (sonnet→opus)"
    echo ""
    echo -e "${BOLD}GUARDIAN OPTIONS${RESET}"
    echo -e "    SKIP_GUARDIAN=true             Skip guardian gates in plan/review/integrate"
    echo ""
    echo -e "${BOLD}PARALLEL FEATURES${RESET}"
    echo -e "    Each ${COLOR_STEP}speed plan${RESET} creates an isolated feature namespace."
    echo -e "    Run multiple features in parallel across separate sessions:"
    echo -e "    ${COLOR_DIM}Session 1:${RESET} ./speed/speed plan specs/tech/auth.md && ./speed/speed run"
    echo -e "    ${COLOR_DIM}Session 2:${RESET} ./speed/speed plan specs/tech/billing.md && ./speed/speed run"
    echo -e "    Use ${COLOR_STEP}--feature${RESET} to target a specific feature, or omit to auto-detect."
    echo ""
    echo -e "${BOLD}EXAMPLES${RESET}"
    echo "    ./speed/speed init"
    echo "    ./speed/speed validate specs/"
    echo "    ./speed/speed plan specs/tech/auth.md --specs-dir specs/"
    echo "    ./speed/speed run"
    echo "    ./speed/speed run --feature billing --max-parallel 3"
    echo "    ./speed/speed status"
    echo "    ./speed/speed review --feature auth"
    echo "    ./speed/speed coherence"
    echo "    ./speed/speed integrate"
    echo "    ./speed/speed clean feature auth"
    echo "    ./speed/speed new prd my-feature"
    echo "    ./speed/speed new defect invite-failure"
    echo ""
}

# ── Commands ─────────────────────────────────────────────────────

cmd_init() {
    log_header "Initializing SPEED"

    # 1. Git repo
    git_ensure_repo
    log_success "Git repository ready"

    # 2. Directory structure
    mkdir -p "$FEATURES_DIR" "$LOGS_DIR" src tests
    log_success "Directory structure created"

    # 3. .gitignore
    if ! grep -q '.speed/features/' "$PROJECT_ROOT/.gitignore" 2>/dev/null; then
        cat >> "$PROJECT_ROOT/.gitignore" << 'EOF'

# SPEED runtime state
.speed/logs/
.speed/features/*/logs/
.speed/features/*/state.json
.speed/features/*/failure_history.jsonl
.speed/active_feature
.speed/state.json
.speed/running/
.speed/worktrees/
EOF
        log_success "Updated .gitignore"
    fi

    # 4. Runtime state (global — for validate and cross-feature use)
    echo '{"status":"idle","agents":[],"started_at":null}' | jq '.' > "${STATE_DIR}/state.json"
    log_success "Runtime state initialized"

    # 5. CLAUDE.md
    if [[ ! -f "$CLAUDE_MD" ]]; then
        local project_name
        project_name=$(basename "$PROJECT_ROOT")
        sed "s/{{PROJECT_NAME}}/${project_name}/g" "${TEMPLATES_DIR}/claude-md.md" > "$CLAUDE_MD"
        log_success "Created CLAUDE.md — ${COLOR_DIM}customize this file!${RESET}"
    else
        log_info "CLAUDE.md already exists, skipping"
    fi

    # 6. speed.toml
    local speed_toml="${PROJECT_ROOT}/speed.toml"
    if [[ ! -f "$speed_toml" ]]; then
        cp "${TEMPLATES_DIR}/speed-toml.toml" "$speed_toml"
        log_success "Created speed.toml — ${COLOR_DIM}configure providers and settings${RESET}"
    else
        log_info "speed.toml already exists, skipping"
    fi

    # 7. Vision file template
    local vision_path="${PROJECT_ROOT}/${VISION_FILE}"
    local vision_dir
    vision_dir=$(dirname "$vision_path")
    if [[ ! -f "$vision_path" ]]; then
        mkdir -p "$vision_dir"
        cp "${TEMPLATES_DIR}/overview.md" "$vision_path"
        log_success "Created ${VISION_FILE} — ${COLOR_DIM}define your product vision${RESET}"
    else
        log_info "${VISION_FILE} already exists, skipping"
    fi

    # 8. Initial commit
    (cd "$PROJECT_ROOT" && git add -A && git commit -m "speed init: project scaffold" 2>/dev/null) || true

    echo ""
    log_success "SPEED initialized! Next steps:"
    echo -e "  1. Edit ${COLOR_STEP}CLAUDE.md${RESET} with your project conventions"
    echo -e "  2. Edit ${COLOR_STEP}speed.toml${RESET} to configure your provider and settings"
    echo -e "  3. Edit ${COLOR_STEP}${VISION_FILE}${RESET} with your product vision"
    echo -e "  4. Create a product spec: ${COLOR_STEP}cp speed/templates/spec.md my-spec.md${RESET}"
    echo -e "  5. Plan your tasks: ${COLOR_STEP}./speed/speed plan my-spec.md${RESET}"
    echo ""
}

cmd_validate() {
    local specs_dir="${1:-}"

    if [[ -z "$specs_dir" ]]; then
        log_error "Usage: speed validate <specs-dir>"
        exit 1
    fi

    if [[ ! -d "$specs_dir" ]]; then
        if [[ -d "${PROJECT_ROOT}/${specs_dir}" ]]; then
            specs_dir="${PROJECT_ROOT}/${specs_dir}"
        else
            log_error "Specs directory not found: $specs_dir"
            exit 1
        fi
    fi

    log_header "Validating Specs"

    # Gather all spec files
    local spec_files=""
    local file_count=0
    while IFS= read -r -d '' f; do
        local relpath="${f#${PROJECT_ROOT}/}"
        spec_files+=$'\n\n'"--- FILE: ${relpath} ---"$'\n'"$(cat "$f")"
        ((file_count++))
    done < <(find "$specs_dir" -name '*.md' -type f -print0 | sort -z)

    if [[ $file_count -eq 0 ]]; then
        log_error "No .md files found in $specs_dir"
        exit 1
    fi

    log_step "Found ${file_count} spec files"
    log_step "Sending to Validator agent..."
    echo ""

    local validator_output
    if ! validator_output=$(claude_run \
        "${AGENTS_DIR}/validator.md" \
        "Cross-validate the following ${file_count} specification files for consistency, completeness, and missing relationships:${spec_files}" \
        "$MODEL_SUPPORT" \
        "$AGENT_TOOLS_READONLY" \
        "Validator"); then
        log_error "Validator agent failed — check Claude CLI connection and authentication"
        exit 1
    fi

    if [[ -z "$validator_output" ]]; then
        log_error "Validator agent returned empty output — check Claude CLI connection and authentication"
        exit 1
    fi

    echo "$validator_output"
    echo ""

    # Save validation report
    echo "$validator_output" > "${LOGS_DIR}/validation.log"
    log_success "Validation report saved to ${LOGS_DIR}/validation.log"

    # Check status
    if ! _require_json "Validator" "$validator_output"; then
        log_error "Review raw output: ${LOGS_DIR}/validation.log"
        exit 1
    fi

    local status
    status=$(echo "$validator_output" | jq -r '.status // "unknown"')

    if [[ "$status" == "fail" ]]; then
        echo ""
        log_error "Validation FAILED — fix critical gaps before running 'speed plan'"
        local gap_count
        gap_count=$(echo "$validator_output" | jq '.critical_gaps | length')
        log_error "${gap_count} critical gap(s) found"
        exit 1
    elif [[ "$status" == "pass" ]]; then
        echo ""
        log_success "Validation PASSED — specs are consistent"
    else
        log_warn "Could not parse validation status. Review the report manually."
    fi

    echo ""
}

# ── Gather related specs for cross-referencing ────────────────

_gather_related_specs() {
    local specs_dir="$1"
    shift
    local exclude_files=("$@")
    local related=""

    if [[ -z "$specs_dir" ]] || [[ ! -d "$specs_dir" ]]; then
        echo ""
        return
    fi

    while IFS= read -r -d '' f; do
        # Skip excluded spec files (primary + auto-derived siblings)
        local skip=false
        local f_real
        f_real=$(realpath "$f")
        for exclude in "${exclude_files[@]}"; do
            if [[ -n "$exclude" ]] && [[ "$f_real" == "$(realpath "$exclude")" ]]; then
                skip=true
                break
            fi
        done
        if [[ "$skip" == "true" ]]; then
            continue
        fi

        local relpath="${f#${PROJECT_ROOT}/}"
        related+=$'\n\n'"--- RELATED SPEC: ${relpath} ---"$'\n'"$(cat "$f")"
    done < <(find "$specs_dir" -name '*.md' -type f -print0 | sort -z)

    echo "$related"
}

# ── Store the primary spec file path for downstream commands ──
# Uses FEATURE_DIR when a feature is active, otherwise STATE_DIR fallback.

_save_spec_path() {
    local spec_file="$1"
    local dir="${FEATURE_DIR:-${STATE_DIR}}"
    echo "$spec_file" > "${dir}/spec_path"
}

_get_spec_path() {
    local dir="${FEATURE_DIR:-${STATE_DIR}}"
    if [[ -f "${dir}/spec_path" ]]; then
        local saved_path
        saved_path=$(cat "${dir}/spec_path")
        if [[ -n "$saved_path" ]] && [[ -f "$saved_path" ]]; then
            echo "$saved_path"
        elif [[ -n "$saved_path" ]]; then
            log_warn "Saved spec path '${saved_path}' no longer exists — was it moved or deleted?"
        fi
    fi
}

# ── Plan stage caching ─────────────────────────────────────────
# Caches expensive stages (Guardian, Architect) keyed by a hash of
# spec inputs. Auto-invalidates when specs change. --force bypasses.

_plan_cache_dir() { echo "${FEATURE_DIR}/cache"; }

_plan_cache_valid() {
    local stage="$1" hash="$2"
    local cache_dir
    cache_dir=$(_plan_cache_dir)
    [[ -f "${cache_dir}/${stage}.hash" && -f "${cache_dir}/${stage}.dat" ]] \
        && [[ "$(cat "${cache_dir}/${stage}.hash")" == "$hash" ]]
}

_plan_cache_write() {
    local stage="$1" hash="$2" data="$3"
    local cache_dir
    cache_dir=$(_plan_cache_dir)
    mkdir -p "$cache_dir"
    echo "$hash" > "${cache_dir}/${stage}.hash"
    echo "$data" > "${cache_dir}/${stage}.dat"
}

_plan_cache_read() {
    cat "$(_plan_cache_dir)/${1}.dat"
}

cmd_plan() {
    local spec_file="${1:-}"
    shift || true
    local specs_dir=""
    local force_plan=false

    # Parse options
    while [[ $# -gt 0 ]]; do
        case "$1" in
            --specs-dir) specs_dir="$2"; shift 2 ;;
            --force) force_plan=true; shift ;;
            *) log_error "Unknown option: $1"; exit 1 ;;
        esac
    done

    if [[ -z "$spec_file" ]]; then
        log_error "Usage: speed plan <tech-spec-file> [--specs-dir DIR]"
        exit 1
    fi

    if [[ ! -f "$spec_file" ]]; then
        # Try relative to PROJECT_ROOT
        if [[ -f "${PROJECT_ROOT}/${spec_file}" ]]; then
            spec_file="${PROJECT_ROOT}/${spec_file}"
        else
            log_error_block \
                "Spec file not found: ${spec_file}" \
                "The plan command requires a spec file" \
                "Create the spec or check the path"
            exit $EXIT_CONFIG_ERROR
        fi
    fi

    # Resolve specs_dir
    if [[ -n "$specs_dir" ]] && [[ ! -d "$specs_dir" ]]; then
        if [[ -d "${PROJECT_ROOT}/${specs_dir}" ]]; then
            specs_dir="${PROJECT_ROOT}/${specs_dir}"
        else
            log_warn "Specs directory not found: $specs_dir — proceeding without cross-references"
            specs_dir=""
        fi
    fi

    # ── Auto-derive sibling specs ──────────────────────────────────
    # Convention: specs/tech/<name>.md → specs/product/<name>.md
    #                                  → specs/design/<name>.md
    local product_spec_file=""
    local design_spec_file=""
    local derived_product
    local derived_design
    derived_product=$(echo "$spec_file" | sed 's|/tech/|/product/|')
    derived_design=$(echo "$spec_file" | sed 's|/tech/|/design/|')

    if [[ "$derived_product" != "$spec_file" ]] && [[ -f "$derived_product" ]]; then
        product_spec_file="$derived_product"
    fi
    if [[ "$derived_design" != "$spec_file" ]] && [[ -f "$derived_design" ]]; then
        design_spec_file="$derived_design"
    fi

    # ── Activate feature namespace ────────────────────────────────
    local feature_name="${GLOBAL_FEATURE:-}"
    if [[ -z "$feature_name" ]]; then
        feature_name=$(feature_name_from_spec "$spec_file")
    fi
    feature_activate "$feature_name"
    feature_set_active "$feature_name"
    log_info "Feature: ${COLOR_STEP}${feature_name}${RESET}"

    # Save spec path for verify and review commands
    _save_spec_path "$spec_file"

    log_header "Planning Task DAG"
    log_step "Tech spec:    ${COLOR_STEP}${spec_file}${RESET}"
    if [[ -n "$product_spec_file" ]]; then
        log_step "Product spec: ${COLOR_STEP}${product_spec_file}${RESET}"
    else
        log_warn "No product spec found (expected: ${derived_product})"
    fi
    if [[ -n "$design_spec_file" ]]; then
        log_step "Design spec:  ${COLOR_STEP}${design_spec_file}${RESET}"
    else
        log_warn "No design spec found (expected: ${derived_design})"
    fi

    # Read all specs
    local tech_spec_content
    tech_spec_content=$(cat "$spec_file")

    local product_spec_content=""
    if [[ -n "$product_spec_file" ]]; then
        product_spec_content=$(cat "$product_spec_file")
    fi

    local design_spec_content=""
    if [[ -n "$design_spec_file" ]]; then
        design_spec_content=$(cat "$design_spec_file")
    fi

    # ── Spec hash for stage caching ───────────────────────────────
    local spec_hash
    spec_hash=$(printf '%s' "${tech_spec_content}${product_spec_content}${design_spec_content}" | shasum -a 256 | cut -d' ' -f1)

    # ── Pre-Plan Guardian Gate ─────────────────────────────────────
    # Check: does this spec belong in the product?
    local guardian_rc=0
    if [[ "$force_plan" != "true" ]] && _plan_cache_valid "guardian" "$spec_hash"; then
        guardian_rc=$(_plan_cache_read "guardian")
        log_step "Guardian: ${COLOR_DIM}cached (specs unchanged)${RESET}"
    else
        log_step "Running pre-plan vision check..."
        local _guardian_out
        _guardian_out=$(_run_guardian "pre-plan" "$tech_spec_content" "$spec_file") || guardian_rc=$?
        _plan_cache_write "guardian" "$spec_hash" "$guardian_rc"
    fi

    if [[ $guardian_rc -eq 1 ]]; then
        log_error "Product Guardian REJECTED this spec — it conflicts with the product vision"
        echo -e "Review the guardian report and either:"
        echo -e "  1. Fix the spec to align with the vision"
        echo -e "  2. Override with ${COLOR_STEP}SKIP_GUARDIAN=true speed plan ...${RESET} (use with caution)"
        if [[ "${SKIP_GUARDIAN:-}" != "true" ]]; then
            exit 1
        else
            log_warn "SKIP_GUARDIAN=true — proceeding despite rejection"
        fi
    elif [[ $guardian_rc -eq 3 ]]; then
        log_warn "Guardian returned unparseable output — proceeding but review the log"
    fi
    # guardian_rc == 2 means flagged — warn but continue
    echo ""

    # ── Spec-Codebase Grounding ────────────────────────────────────
    # Check: does the spec accurately describe the current codebase?
    SPEC_CODEBASE_CONTEXT=""
    spec_grounding_check "$spec_file"

    # Gather related specs for cross-referencing
    local related_specs=""
    if [[ -n "$specs_dir" ]]; then
        log_step "Gathering related specs from: ${COLOR_STEP}${specs_dir}${RESET}"
        related_specs=$(_gather_related_specs "$specs_dir" "$spec_file" "$product_spec_file" "$design_spec_file")
        if [[ -n "$related_specs" ]]; then
            log_step "Cross-referencing with related specs"
        fi
    fi

    # ── Architect agent ───────────────────────────────────────────
    local parsed_architect

    if [[ "$force_plan" != "true" ]] && _plan_cache_valid "architect" "$spec_hash"; then
        parsed_architect=$(_plan_cache_read "architect")
        log_step "Architect: ${COLOR_DIM}cached (specs unchanged)${RESET}"
        echo ""
    else
        log_step "Sending to Architect agent..."
        echo ""

        # Build structured architect message
        # Three specs (product + tech + design) + grounding context + related specs.
        local architect_message=""

        if [[ -n "$product_spec_content" ]]; then
            architect_message+="## Product Spec (what to build)\n\n${product_spec_content}"
        fi

        architect_message+="\n\n## Tech Spec (backend implementation)\n\n${tech_spec_content}"

        if [[ -n "$design_spec_content" ]]; then
            architect_message+="\n\n## Design Spec (frontend implementation)\n\n${design_spec_content}"
        fi

        if [[ -n "$SPEC_CODEBASE_CONTEXT" ]]; then
            architect_message+="\n\n## Codebase Context (ground truth from automated scan)\n\n${SPEC_CODEBASE_CONTEXT}"
        fi

        if [[ -n "$related_specs" ]]; then
            architect_message+="\n\n## Related Specs (cross-reference for entity relationships)\n${related_specs}"
        fi

        # Full tools, generous turns — the Architect explores the codebase
        # to produce an informed plan. Timeout is the real safety bound.
        local architect_output
        local architect_rc=0
        architect_output=$(claude_run_json \
            "${AGENTS_DIR}/architect.md" \
            "$architect_message" \
            "${TEMPLATES_DIR}/architect-output.json" \
            "$MODEL_PLANNING" \
            "$ARCHITECT_MAX_TURNS" \
            "" \
            "Architect") || architect_rc=$?

        # Save raw output for debugging
        echo "$architect_output" > "${LOGS_DIR}/architect-raw.log"

        # Check for architect failure
        if [[ $architect_rc -ne 0 ]]; then
            log_error "Architect agent failed (exit code ${architect_rc})"
            if [[ $architect_rc -eq 2 ]]; then
                log_error "The architect returned an error envelope — check ${LOGS_DIR}/architect-raw.log"
            fi
            log_error "Raw output saved to ${LOGS_DIR}/architect-raw.log"
            exit 1
        fi

        # Parse architect output
        parsed_architect=$(parse_agent_json "$architect_output") || {
            log_error "Could not extract valid JSON from architect output"
            log_error "Raw output saved to ${LOGS_DIR}/architect-raw.log"
            echo -e "${COLOR_DIM}First 5 lines of output:${RESET}" >&2
            echo "$architect_output" | head -5 | while IFS= read -r line; do
                echo -e "  ${COLOR_DIM}${line}${RESET}" >&2
            done
            exit 1
        }

        # Cache successful architect output
        _plan_cache_write "architect" "$spec_hash" "$parsed_architect"
    fi

    # ── Validation gate ────────────────────────────────────────────
    # The architect validates coverage across product, tech, and design specs.
    # Critical issues = hard block. Warnings/notes = proceed with logging.
    local validation_json
    validation_json=$(echo "$parsed_architect" | jq '.validation // []')
    local validation_count
    validation_count=$(echo "$validation_json" | jq 'length')

    if [[ "$validation_count" -gt 0 ]]; then
        echo ""
        log_header "Validation Report"
        local has_critical=false
        local i=0
        while [[ $i -lt $validation_count ]]; do
            local severity issue product_req recommendation
            severity=$(echo "$validation_json" | jq -r ".[$i].severity")
            issue=$(echo "$validation_json" | jq -r ".[$i].issue")
            product_req=$(echo "$validation_json" | jq -r ".[$i].product_requirement")
            recommendation=$(echo "$validation_json" | jq -r ".[$i].recommendation")

            case "$severity" in
                critical)
                    echo -e "  ${COLOR_ERROR}${SYM_CROSS} CRITICAL:${RESET} ${issue}"
                    echo -e "    ${COLOR_DIM}Requirement:${RESET} ${product_req}"
                    echo -e "    ${COLOR_DIM}Fix:${RESET} ${recommendation}"
                    has_critical=true
                    ;;
                warning)
                    echo -e "  ${COLOR_WARN}${SYM_WARN} WARNING:${RESET} ${issue}"
                    echo -e "    ${COLOR_DIM}Requirement:${RESET} ${product_req}"
                    echo -e "    ${COLOR_DIM}Suggestion:${RESET} ${recommendation}"
                    ;;
                note)
                    echo -e "  ${COLOR_STEP}${SYM_DOT} NOTE:${RESET} ${issue}"
                    echo -e "    ${COLOR_DIM}${recommendation}${RESET}"
                    ;;
            esac
            echo ""
            ((i++))
        done

        # Persist validation report
        echo "$validation_json" | jq '.' > "${LOGS_DIR}/validation-report.json"
        log_step "Validation report saved to ${LOGS_DIR}/validation-report.json"

        # Hard gate: critical issues block task creation
        if [[ "$has_critical" == "true" ]]; then
            log_error "Architect found CRITICAL validation issues — cannot create tasks"
            echo -e "Fix the spec issues above and re-run ${COLOR_STEP}speed plan${RESET}"
            exit 1
        fi
    else
        log_success "Validation clean — no issues found"
    fi
    echo ""

    # ── Extract tasks and contract ─────────────────────────────────
    local tasks_json=""
    local contract_json=""

    if echo "$parsed_architect" | jq -e '.tasks | type == "array"' &>/dev/null; then
        tasks_json=$(echo "$parsed_architect" | jq '.tasks')
        contract_json=$(echo "$parsed_architect" | jq '.contract // empty')
    else
        log_error "Architect output missing 'tasks' array"
        log_error "Raw output saved to ${LOGS_DIR}/architect-raw.log"
        exit 1
    fi

    # Save contract
    if [[ -n "$contract_json" ]] && echo "$contract_json" | jq -e '.' &>/dev/null; then
        echo "$contract_json" | jq '.' > "${CONTRACT_FILE}"
        log_success "Contract saved to ${CONTRACT_FILE}"
    else
        log_warn "No contract produced — verification will be limited"
    fi

    # Clear existing tasks
    rm -f "${TASKS_DIR}"/*.json

    # Parse and create task files
    local task_count
    task_count=$(echo "$tasks_json" | jq 'length')

    if [[ "$task_count" -eq 0 ]]; then
        log_error "Architect produced 0 tasks"
        log_error "Raw output saved to ${LOGS_DIR}/architect-raw.log"
        exit 1
    fi

    log_step "Creating ${task_count} tasks..."
    echo ""

    local i=0
    while [[ $i -lt $task_count ]]; do
        local task
        task=$(echo "$tasks_json" | jq ".[$i]")

        local id title description criteria depends_on model files_touched
        id=$(echo "$task" | jq -r '.id')
        title=$(echo "$task" | jq -r '.title')
        description=$(echo "$task" | jq -r '.description')
        criteria=$(echo "$task" | jq -r '.acceptance_criteria')
        depends_on=$(echo "$task" | jq -c '.depends_on // []')
        model=$(echo "$task" | jq -r --arg def "$MODEL_SUPPORT" '.agent_model // $def')
        files_touched=$(echo "$task" | jq -c '.files_touched // []')

        task_create "$id" "$title" "$description" "$criteria" "$depends_on" "$model"

        # Store files_touched in the task file
        if [[ "$files_touched" != "[]" ]]; then
            task_update_raw "$id" "files_touched" "$files_touched"
        fi

        ((i++))
    done

    log_success "Task DAG created with ${task_count} tasks"
    echo ""

    # Display task graph
    log_header "Task Graph"
    task_print_graph
    echo ""
    task_print_summary
    echo ""

    echo -e "${COLOR_DIM}Review tasks in ${TASKS_DIR}/${RESET}"
    echo -e "${COLOR_DIM}Next: ${COLOR_STEP}./speed/speed verify${RESET} to validate the plan against the spec${RESET}"
    echo ""
}

# ── Gates: run quality gates for a task ──────────────────────

cmd_gates() {
    # Support -f/--feature as local flag so copy-pasteable commands work
    # regardless of flag position (before or after the subcommand)
    local local_args=()
    while [[ $# -gt 0 ]]; do
        case "$1" in
            -f|--feature) GLOBAL_FEATURE="$2"; shift 2 ;;
            *) local_args+=("$1"); shift ;;
        esac
    done
    set -- "${local_args[@]+"${local_args[@]}"}"

    _require_feature "$GLOBAL_FEATURE"

    local task_id=""
    local mode="fast"
    local worktree_flag=""

    # Parse local flags
    while [[ $# -gt 0 ]]; do
        case "$1" in
            --task)      task_id="$2"; shift 2 ;;
            --fast)      mode="fast"; shift ;;
            --full)      mode="full"; shift ;;
            --worktree)  worktree_flag="$2"; shift 2 ;;
            *) log_error "Unknown option: $1"; exit 1 ;;
        esac
    done

    # Validate required flags
    if [[ -z "$task_id" ]]; then
        log_error "Required: --task ID"
        echo "Usage: ./speed/speed gates -f <feature> --task <id> [--fast|--full] [--worktree <path>]"
        exit 1
    fi

    # Resolve worktree path
    local worktree_path
    if [[ -n "$worktree_flag" ]]; then
        worktree_path="$worktree_flag"
    elif [[ -d "${WORKTREES_DIR}/task-${task_id}" ]]; then
        worktree_path="${WORKTREES_DIR}/task-${task_id}"
    else
        worktree_path="${PROJECT_ROOT}"
    fi

    log_header "Quality Gates (${mode})"
    log_info "Task: ${task_id} | Worktree: ${worktree_path}"

    if [[ "$mode" == "full" ]]; then
        # Full mode: delegate entirely to gates_run (grounding + all quality gates)
        if gates_run "$task_id" "$worktree_path"; then
            log_success "All gates passed"
            exit 0
        else
            log_error "One or more gates failed"
            exit 1
        fi
    fi

    # Fast mode: syntax check + lint + typecheck only (no grounding, no tests)
    local subsystem
    subsystem=$(_detect_subsystem "$task_id")
    log_step "Subsystem: ${subsystem}"

    local results=()
    local all_passed=true

    # Syntax check
    if gate_syntax_check "$task_id" "$worktree_path"; then
        results+=("${COLOR_SUCCESS}${SYM_CHECK} Syntax check${RESET}")
    else
        results+=("${COLOR_ERROR}${SYM_CROSS} Syntax check${RESET}")
        all_passed=false
    fi

    # Lint
    local cmds
    cmds=$(gates_get_config "lint" "$subsystem")
    if [[ -n "$cmds" ]]; then
        while IFS= read -r cmd; do
            [[ -z "$cmd" ]] && continue
            if gate_run_command "Lint" "$cmd" "$worktree_path"; then
                results+=("${COLOR_SUCCESS}${SYM_CHECK} Lint: ${COLOR_DIM}${cmd}${RESET}")
            else
                results+=("${COLOR_ERROR}${SYM_CROSS} Lint: ${COLOR_DIM}${cmd}${RESET}")
                all_passed=false
            fi
        done <<< "$cmds"
    fi

    # Typecheck
    cmds=$(gates_get_config "typecheck" "$subsystem")
    if [[ -n "$cmds" ]]; then
        while IFS= read -r cmd; do
            [[ -z "$cmd" ]] && continue
            if gate_run_command "Typecheck" "$cmd" "$worktree_path"; then
                results+=("${COLOR_SUCCESS}${SYM_CHECK} Typecheck: ${COLOR_DIM}${cmd}${RESET}")
            else
                results+=("${COLOR_ERROR}${SYM_CROSS} Typecheck: ${COLOR_DIM}${cmd}${RESET}")
                all_passed=false
            fi
        done <<< "$cmds"
    fi

    # Print results
    echo ""
    echo -e "  ${BOLD}Quality Gates (fast):${RESET}"
    for r in "${results[@]}"; do
        echo -e "    $r"
    done
    echo ""

    if $all_passed; then
        log_success "All fast gates passed"
        exit 0
    else
        log_error "One or more gates failed"
        exit 1
    fi
}

# ── Verify: blind plan verification against product spec ─────

# Format structured verification JSON into a human-readable report.
# Uses the same visual style as gates_run() output.
# Usage: _print_verify_report "$verify_json"
_print_verify_report() {
    local json="$1"

    echo ""
    echo -e "  ${BOLD}Verification Report:${RESET}"

    # 1. Core question
    local answerable
    answerable=$(echo "$json" | jq -r '.core_question_answerable // empty' 2>/dev/null)
    if [[ "$answerable" == "true" ]]; then
        echo -e "    ${COLOR_SUCCESS}${SYM_CHECK} Core question: answerable${RESET}"
    elif [[ "$answerable" == "false" ]]; then
        echo -e "    ${COLOR_ERROR}${SYM_CROSS} Core question: not answerable${RESET}"
    fi

    # 2. Spec requirements
    local total_reqs covered_reqs
    total_reqs=$(echo "$json" | jq '[.spec_requirements // [] | .[] ] | length' 2>/dev/null) || total_reqs=0
    covered_reqs=$(echo "$json" | jq '[.spec_requirements // [] | .[] | select(.status == "covered")] | length' 2>/dev/null) || covered_reqs=0

    if [[ "$total_reqs" -gt 0 ]]; then
        echo -e "    ${BOLD}Spec requirements:${RESET} ${covered_reqs} of ${total_reqs} covered"

        # Print non-covered requirements
        local non_covered
        non_covered=$(echo "$json" | jq -c '.spec_requirements // [] | .[] | select(.status == "covered" | not)' 2>/dev/null)
        while IFS= read -r req; do
            [[ -z "$req" ]] && continue
            local req_text req_status spec_says plan_says task_id
            req_text=$(echo "$req" | jq -r '.requirement // "unknown"')
            req_status=$(echo "$req" | jq -r '.status // "unknown"')
            spec_says=$(echo "$req" | jq -r '.spec_says // empty')
            plan_says=$(echo "$req" | jq -r '.plan_says // empty')
            task_id=$(echo "$req" | jq -r '.task // empty')

            echo -e "    ${COLOR_ERROR}${SYM_CROSS} ${req_text} ${COLOR_DIM}(status: ${req_status})${RESET}"
            if [[ -n "$spec_says" ]] || [[ -n "$plan_says" ]] || [[ -n "$task_id" ]]; then
                local detail=""
                [[ -n "$spec_says" ]] && detail+="Spec says: ${spec_says}"
                [[ -n "$plan_says" ]] && { [[ -n "$detail" ]] && detail+=" | "; detail+="Plan says: ${plan_says}"; }
                [[ -n "$task_id" ]] && { [[ -n "$detail" ]] && detail+=" | "; detail+="Task: ${task_id}"; }
                echo -e "      ${COLOR_DIM}${detail}${RESET}"
            fi
        done <<< "$non_covered"
    fi

    # 3. Semantic drift
    local drift_count
    drift_count=$(echo "$json" | jq '[.semantic_drift // [] | .[]] | length' 2>/dev/null) || drift_count=0
    if [[ "$drift_count" -gt 0 ]]; then
        echo "$json" | jq -c '.semantic_drift[] ' 2>/dev/null | while IFS= read -r drift; do
            [[ -z "$drift" ]] && continue
            local spec_term plan_term risk
            spec_term=$(echo "$drift" | jq -r '.spec_term // "?"')
            plan_term=$(echo "$drift" | jq -r '.plan_term // "?"')
            risk=$(echo "$drift" | jq -r '.risk // ""')
            echo -e "    ${COLOR_WARN}${SYM_WARN} \"${spec_term}\" ${SYM_ARROW} \"${plan_term}\": ${risk}${RESET}"
        done
    fi

    # 4. Critical failures
    local failure_count
    failure_count=$(echo "$json" | jq '[.critical_failures // [] | .[]] | length' 2>/dev/null) || failure_count=0
    if [[ "$failure_count" -gt 0 ]]; then
        echo "$json" | jq -c '.critical_failures[]' 2>/dev/null | while IFS= read -r failure; do
            [[ -z "$failure" ]] && continue
            local desc spec_ref plan_gap
            desc=$(echo "$failure" | jq -r '.description // "unknown"')
            spec_ref=$(echo "$failure" | jq -r '.spec_reference // empty')
            plan_gap=$(echo "$failure" | jq -r '.plan_gap // empty')

            echo -e "    ${COLOR_ERROR}${SYM_CROSS} ${desc}${RESET}"
            if [[ -n "$spec_ref" ]] || [[ -n "$plan_gap" ]]; then
                local detail=""
                [[ -n "$spec_ref" ]] && detail+="Spec: ${spec_ref}"
                [[ -n "$plan_gap" ]] && { [[ -n "$detail" ]] && detail+=" | "; detail+="Gap: ${plan_gap}"; }
                echo -e "      ${COLOR_DIM}${detail}${RESET}"
            fi
        done
    fi

    # 5. Recommendations
    local rec_count
    rec_count=$(echo "$json" | jq '[.recommendations // [] | .[]] | length' 2>/dev/null) || rec_count=0
    if [[ "$rec_count" -gt 0 ]]; then
        echo "$json" | jq -r '.recommendations[]' 2>/dev/null | while IFS= read -r rec; do
            [[ -z "$rec" ]] && continue
            echo -e "    ${COLOR_INFO}${SYM_ARROW} ${rec}${RESET}"
        done
    fi

    # 6. Summary line
    local warn_count="$drift_count"
    echo ""
    echo -e "  ${BOLD}Summary:${RESET} ${failure_count} critical, ${warn_count} warnings, ${rec_count} recommendations"
    echo ""
}

# Print human escalation for needs_human items from Fix Agent output.
# Usage: _print_human_escalation "$fix_json"
_print_human_escalation() {
    local fix_json="$1"

    echo ""
    echo -e "  ${COLOR_WARN}Cannot auto-fix — requires your judgment:${RESET}"
    echo ""

    echo "$fix_json" | jq -c '.needs_human // [] | .[]' 2>/dev/null | while IFS= read -r item; do
        [[ -z "$item" ]] && continue
        local task_id file issue spec_says plan_says
        task_id=$(echo "$item" | jq -r '.task_id // "?"')
        file=$(echo "$item" | jq -r '.file // "?"')
        issue=$(echo "$item" | jq -r '.issue // "unknown"')
        spec_says=$(echo "$item" | jq -r '.spec_says // empty')
        plan_says=$(echo "$item" | jq -r '.plan_says // empty')

        echo -e "  Task ${task_id} (${COLOR_DIM}${file}${RESET}):"
        echo -e "    ${COLOR_DIM}Issue: ${issue}${RESET}"
        [[ -n "$spec_says" ]] && echo -e "    ${COLOR_DIM}Spec says: ${spec_says}${RESET}"
        [[ -n "$plan_says" ]] && echo -e "    ${COLOR_DIM}Plan says: ${plan_says}${RESET}"

        local options
        options=$(echo "$item" | jq -r '.options // [] | .[]' 2>/dev/null)
        if [[ -n "$options" ]]; then
            local opt_num=0
            echo -e "    ${COLOR_DIM}Options:${RESET}"
            echo "$options" | while IFS= read -r opt; do
                ((opt_num++))
                echo -e "      ${COLOR_DIM}${opt_num}. ${opt}${RESET}"
            done
        fi
        echo ""
    done

    echo -e "  After fixing, run: ${COLOR_STEP}speed verify${RESET}"
    echo ""
}

# Print human escalation from verification JSON (critical failures + needs_human items).
# Usage: _print_human_escalation_from_verify "$verify_json"
_print_human_escalation_from_verify() {
    local verify_json="$1"

    local cf_count nh_count
    cf_count=$(echo "$verify_json" | jq '[.critical_failures // [] | .[]] | length' 2>/dev/null) || cf_count=0
    nh_count=$(echo "$verify_json" | jq '[.needs_human // [] | .[]] | length' 2>/dev/null) || nh_count=0
    [[ "$cf_count" -eq 0 ]] && [[ "$nh_count" -eq 0 ]] && return

    echo ""
    echo -e "  ${COLOR_WARN}Cannot auto-fix — requires your judgment:${RESET}"
    echo ""

    # Print critical failures
    echo "$verify_json" | jq -c '.critical_failures // [] | .[]' 2>/dev/null | while IFS= read -r failure; do
        [[ -z "$failure" ]] && continue
        local desc spec_ref plan_gap
        desc=$(echo "$failure" | jq -r '.description // "unknown"')
        spec_ref=$(echo "$failure" | jq -r '.spec_reference // empty')
        plan_gap=$(echo "$failure" | jq -r '.plan_gap // empty')

        echo -e "    ${COLOR_DIM}Issue: ${desc}${RESET}"
        [[ -n "$spec_ref" ]] && echo -e "    ${COLOR_DIM}Spec says: ${spec_ref}${RESET}"
        [[ -n "$plan_gap" ]] && echo -e "    ${COLOR_DIM}Plan says: ${plan_gap}${RESET}"
        echo ""
    done

    # Print needs_human items (if verifier classified them separately)
    echo "$verify_json" | jq -c '.needs_human // [] | .[]' 2>/dev/null | while IFS= read -r item; do
        [[ -z "$item" ]] && continue
        local desc spec_ref plan_gap
        desc=$(echo "$item" | jq -r '.description // "unknown"')
        spec_ref=$(echo "$item" | jq -r '.spec_reference // empty')
        plan_gap=$(echo "$item" | jq -r '.plan_gap // empty')

        echo -e "    ${COLOR_DIM}Issue: ${desc}${RESET}"
        [[ -n "$spec_ref" ]] && echo -e "    ${COLOR_DIM}Spec says: ${spec_ref}${RESET}"
        [[ -n "$plan_gap" ]] && echo -e "    ${COLOR_DIM}Plan says: ${plan_gap}${RESET}"
        echo ""
    done

    echo -e "  After fixing, run: ${COLOR_STEP}speed verify${RESET}"
    echo ""
}

# Print fix summary after auto-fix loop completes.
# Usage: _print_fix_summary "$all_fixes_json" "$total_fixes"
_print_fix_summary() {
    local fixes_json="$1"
    local count="$2"

    echo ""
    echo -e "  ${BOLD}Auto-fixed ${count} issue(s):${RESET}"

    echo "$fixes_json" | jq -c '.[]' 2>/dev/null | while IFS= read -r fix; do
        [[ -z "$fix" ]] && continue
        local task_id field before after
        task_id=$(echo "$fix" | jq -r '.task_id // "?"')
        field=$(echo "$fix" | jq -r '.field // "?"')
        before=$(echo "$fix" | jq -r '.before // "?"')
        after=$(echo "$fix" | jq -r '.after // "?"')
        local reason
        reason=$(echo "$fix" | jq -r '.reason // empty')
        echo -e "    Task ${task_id}: ${field} ${before} ${SYM_ARROW} ${after}${reason:+ (${reason})}"
    done
    echo ""
}

# Build the verification message from current task plan + spec + contract.
# IMPORTANT (load-bearing): This function intentionally sets variables in caller scope — no 'local'
# inside. The caller MUST declare these as local before calling, e.g.:
#   local task_plan="" contract_section="" verify_message=""
#   _build_verify_message
# Sets variables: task_plan, contract_section, verify_message
# Requires: spec_content (set by caller), TASKS_DIR, CONTRACT_FILE
_build_verify_message() {
    task_plan=""
    for f in "${TASKS_DIR}"/*.json; do
        [[ -f "$f" ]] || continue
        local id title desc criteria deps files
        id=$(jq -r '.id' "$f")
        title=$(jq -r '.title' "$f")
        desc=$(jq -r '.description' "$f")
        criteria=$(jq -r '.acceptance_criteria' "$f")
        deps=$(jq -r '.depends_on | join(", ")' "$f")
        files=$(jq -r '.files_touched // [] | join(", ")' "$f")

        task_plan+="### Task ${id}: ${title}
Description: ${desc}
Acceptance Criteria: ${criteria}
Depends On: ${deps}
Files: ${files}

"
    done

    contract_section=""
    if [[ -f "${CONTRACT_FILE}" ]]; then
        contract_section="
## Data Model Contract
$(cat "${CONTRACT_FILE}")
"
    fi

    verify_message="## Product Specification

${spec_content}

## Task Plan

${task_plan}
${contract_section}

Verify this plan against the product specification. Read the spec FIRST, form your own understanding, THEN check the plan."
}

cmd_verify() {
    _require_feature "$GLOBAL_FEATURE"
    log_header "Verifying Plan Against Spec"

    # Check prerequisites
    local total
    total=$(task_count_total)
    if [[ "$total" -eq 0 ]]; then
        log_error "No tasks found. Run 'speed plan <spec>' first."
        exit 1
    fi

    local spec_file
    spec_file=$(_get_spec_path)
    if [[ -z "$spec_file" ]] || [[ ! -f "$spec_file" ]]; then
        log_error "Product spec not found. Run 'speed plan <spec-file>' first."
        exit 1
    fi

    log_step "Reading product spec: ${COLOR_STEP}${spec_file}${RESET}"
    local spec_content
    spec_content=$(cat "$spec_file")

    # Build verification message from current task plan + spec + contract
    log_step "Gathering task plan (${total} tasks)..."
    local task_plan="" contract_section="" verify_message=""
    _build_verify_message

    log_step "Sending to Plan Verifier agent (blind check)..."
    echo ""

    local verify_output
    if ! verify_output=$(claude_run \
        "${AGENTS_DIR}/plan-verifier.md" \
        "$verify_message" \
        "$MODEL_PLANNING" \
        "$AGENT_TOOLS_READONLY" \
        "Verifier"); then
        log_error "Plan Verifier agent failed — check Claude CLI connection"
        exit 1
    fi

    if [[ -z "$verify_output" ]]; then
        log_error "Plan Verifier agent returned empty output"
        exit 1
    fi

    # Save raw output to log
    echo "$verify_output" > "${LOGS_DIR}/plan-verification.log"
    log_success "Verification report saved to ${LOGS_DIR}/plan-verification.log"

    # Parse JSON from agent output (handles markdown, code fences, prose)
    local verify_json
    verify_json=$(parse_agent_json "$verify_output") || {
        log_error "Plan Verifier returned unparseable output"
        log_error "Review raw output: ${LOGS_DIR}/plan-verification.log"
        exit 1
    }

    # Print human-readable report
    _print_verify_report "$verify_json"

    # Extract status and act on it
    local status
    status=$(echo "$verify_json" | jq -r '.status // "unknown"')

    if [[ "$status" == "pass" ]]; then
        log_success "Plan verification PASSED"
        echo -e "Next: ${COLOR_STEP}./speed/speed run${RESET} to execute tasks"
        echo ""
        return
    elif [[ "$status" != "fail" ]]; then
        log_warn "Could not parse verification status. Review the report manually."
        echo ""
        return
    fi

    # ── Status is "fail" — attempt auto-fix loop ─────────────────
    local failure_count rec_count_init verify_needs_human_count
    failure_count=$(echo "$verify_json" | jq '[.critical_failures // [] | .[]] | length' 2>/dev/null) || failure_count=0
    rec_count_init=$(echo "$verify_json" | jq '[.recommendations // [] | .[]] | length' 2>/dev/null) || rec_count_init=0
    verify_needs_human_count=$(echo "$verify_json" | jq '[.needs_human // [] | .[]] | length' 2>/dev/null) || verify_needs_human_count=0
    log_error "Plan verification FAILED — ${failure_count} critical issue(s) found"

    # If verifier classified all issues as needing human judgment, skip the fix loop (AC #14)
    if [[ "$verify_needs_human_count" -gt 0 ]] && [[ "$failure_count" -eq 0 ]] && [[ "$rec_count_init" -eq 0 ]]; then
        log_warn "All issues require human judgment — skipping auto-fix"
        _print_human_escalation_from_verify "$verify_json"
        exit 1
    fi

    # Gather task file contents for the Fix Agent
    local task_files_content=""
    for f in "${TASKS_DIR}"/*.json; do
        [[ -f "$f" ]] || continue
        task_files_content+="--- FILE: ${f} ---"$'\n'"$(cat "$f")"$'\n\n'
    done

    # Build the issues payload (critical_failures + recommendations)
    local issues_json
    issues_json=$(echo "$verify_json" | jq -c '{
        critical_failures: (.critical_failures // []),
        recommendations: (.recommendations // [])
    }' 2>/dev/null)

    # Track all fixes across iterations for the final summary
    local all_fixes_json="[]"
    local total_fixes=0
    local iteration=0
    local prev_failure_keys=""

    while [[ $iteration -lt $MAX_VERIFY_FIX_ITERATIONS ]]; do
        ((iteration++))

        # Check if there are any auto-fixable issues
        local cf_count rec_count
        cf_count=$(echo "$issues_json" | jq '[.critical_failures // [] | .[]] | length' 2>/dev/null) || cf_count=0
        rec_count=$(echo "$issues_json" | jq '[.recommendations // [] | .[]] | length' 2>/dev/null) || rec_count=0

        if [[ "$cf_count" -eq 0 ]] && [[ "$rec_count" -eq 0 ]]; then
            break
        fi

        log_step "Fix attempt ${iteration}/${MAX_VERIFY_FIX_ITERATIONS}..."

        # Build Fix Agent system prompt (inline — no agent .md file)
        local fix_system_prompt
        fix_system_prompt=$(mktemp)
        cat > "$fix_system_prompt" << 'FIXPROMPT'
# Role: Plan Fix Agent

You are a mechanical fix agent. You receive a verification report listing issues with task JSON files, and the task files themselves. Your job is to apply ONLY the fixes described. Do NOT change anything else.

## Rules

- Read each issue in the verification report
- Determine if it can be fixed by editing a task JSON file (e.g., adjusting a threshold, adding missing detail, fixing a field value)
- If an issue requires human judgment (ambiguous spec interpretation, architectural decisions, trade-offs between approaches), do NOT fix it — add it to `needs_human`
- Apply fixes by editing the task JSON files directly using Write tool
- Report exactly what you changed

## Output Format

```json
{
  "fixes_applied": [
    {
      "task_id": "1",
      "file": "path/to/task-1.json",
      "field": "field_name",
      "before": "old value",
      "after": "new value",
      "reason": "why this fix"
    }
  ],
  "needs_human": [
    {
      "task_id": "1",
      "file": "path/to/task-1.json",
      "issue": "description of the issue",
      "spec_says": "what the spec requires",
      "plan_says": "what the plan currently has",
      "options": ["option 1", "option 2"]
    }
  ]
}
```
FIXPROMPT

        local fix_message="## Verification Issues to Fix

${issues_json}

## Task Files

${task_files_content}

Apply ONLY the fixes described above. Do NOT change anything else."

        local fix_output
        if ! fix_output=$(claude_run \
            "$fix_system_prompt" \
            "$fix_message" \
            "$MODEL_SUPPORT" \
            "$AGENT_TOOLS_WRITE" \
            "FixAgent"); then
            rm -f "$fix_system_prompt"
            log_error "Fix Agent failed — skipping auto-fix"
            break
        fi
        rm -f "$fix_system_prompt"

        if [[ -z "$fix_output" ]]; then
            log_error "Fix Agent returned empty output — skipping"
            break
        fi

        # Parse Fix Agent output
        local fix_json
        fix_json=$(parse_agent_json "$fix_output") || {
            log_error "Fix Agent returned unparseable output — skipping"
            break
        }

        # Log applied fixes
        local fix_count
        fix_count=$(echo "$fix_json" | jq '[.fixes_applied // [] | .[]] | length' 2>/dev/null) || fix_count=0

        if [[ "$fix_count" -gt 0 ]]; then
            echo "$fix_json" | jq -c '.fixes_applied[]' 2>/dev/null | while IFS= read -r fix; do
                [[ -z "$fix" ]] && continue
                local fix_task fix_field fix_before fix_after
                fix_task=$(echo "$fix" | jq -r '.task_id // "?"')
                fix_field=$(echo "$fix" | jq -r '.field // "?"')
                fix_before=$(echo "$fix" | jq -r '.before // "?"')
                fix_after=$(echo "$fix" | jq -r '.after // "?"')
                echo -e "  ${COLOR_SUCCESS}Auto-fixed: Task ${fix_task} — ${fix_field}: ${fix_before} ${SYM_ARROW} ${fix_after}${RESET}"
            done
            # Accumulate fixes for summary
            all_fixes_json=$(echo "$all_fixes_json" "$fix_json" | jq -s '.[0] + (.[1].fixes_applied // [])' 2>/dev/null)
            total_fixes=$((total_fixes + fix_count))
        fi

        # Print human escalation for needs_human items
        local human_count
        human_count=$(echo "$fix_json" | jq '[.needs_human // [] | .[]] | length' 2>/dev/null) || human_count=0

        if [[ "$human_count" -gt 0 ]]; then
            _print_human_escalation "$fix_json"
        fi

        # If no fixes were applied and all issues need human judgment, stop
        if [[ "$fix_count" -eq 0 ]]; then
            log_warn "No auto-fixable issues — all require human judgment"
            break
        fi

        # Re-run Plan Verifier
        log_step "Re-verifying plan after fixes..."
        echo ""

        # Re-build verification message (task files may have been edited by Fix Agent)
        _build_verify_message

        # Intentionally reuses verify_output (same local declared at top of function),
        # overwriting the initial verification result — correct, as only the latest
        # verification result matters within this loop.
        if ! verify_output=$(claude_run \
            "${AGENTS_DIR}/plan-verifier.md" \
            "$verify_message" \
            "$MODEL_PLANNING" \
            "$AGENT_TOOLS_READONLY" \
            "Verifier"); then
            log_error "Re-verification failed — check Claude CLI connection"
            break
        fi

        if [[ -z "$verify_output" ]]; then
            log_error "Re-verification returned empty output"
            break
        fi

        # Save and parse re-verification
        echo "$verify_output" > "${LOGS_DIR}/plan-verification.log"

        verify_json=$(parse_agent_json "$verify_output") || {
            log_error "Re-verification returned unparseable output"
            break
        }

        _print_verify_report "$verify_json"

        status=$(echo "$verify_json" | jq -r '.status // "unknown"')

        if [[ "$status" == "pass" ]]; then
            _print_fix_summary "$all_fixes_json" "$total_fixes"
            log_success "Plan verification PASSED (${total_fixes} issues auto-fixed)"
            echo -e "Next: ${COLOR_STEP}./speed/speed run${RESET} to execute tasks"
            echo ""
            return
        fi

        # Convergence check: extract current failure keys and compare
        local current_failure_keys
        current_failure_keys=$(echo "$verify_json" | jq -r '[.critical_failures // [] | .[] | .description] | sort | join("|||")' 2>/dev/null)

        if [[ "$current_failure_keys" == "$prev_failure_keys" ]] && [[ -n "$current_failure_keys" ]]; then
            log_warn "Same critical failures persist after fix — escalating to human"
            _print_human_escalation_from_verify "$verify_json"
            break
        fi

        prev_failure_keys="$current_failure_keys"

        # Update issues for next iteration
        issues_json=$(echo "$verify_json" | jq -c '{
            critical_failures: (.critical_failures // []),
            recommendations: (.recommendations // [])
        }' 2>/dev/null)

        # Re-gather task files (they may have been edited)
        task_files_content=""
        for f in "${TASKS_DIR}"/*.json; do
            [[ -f "$f" ]] || continue
            task_files_content+="--- FILE: ${f} ---"$'\n'"$(cat "$f")"$'\n\n'
        done
    done

    # Loop exhausted or broke — print final summary
    if [[ "$total_fixes" -gt 0 ]]; then
        _print_fix_summary "$all_fixes_json" "$total_fixes"
    fi

    if [[ "$status" == "fail" ]]; then
        failure_count=$(echo "$verify_json" | jq '[.critical_failures // [] | .[]] | length' 2>/dev/null) || failure_count=0
        log_error "Plan verification FAILED — ${failure_count} critical issue(s) remain after ${iteration} fix attempt(s)"
        _print_human_escalation_from_verify "$verify_json"
        echo ""
        exit 1
    fi
}

cmd_run() {
    _require_feature "$GLOBAL_FEATURE"

    local max_parallel=$DEFAULT_MAX_PARALLEL
    local model=$MODEL_SUPPORT
    local run_start=$SECONDS

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case "$1" in
            --max-parallel) max_parallel="$2"; shift 2 ;;
            --model)        model="$2"; shift 2 ;;
            *) log_error "Unknown option: $1"; exit 1 ;;
        esac
    done

    # ── Acquire exclusive lock ────────────────────────────────────
    speed_acquire_lock "run" || exit 1

    # ── Hard gate: timeout command is required ────────────────────
    require_timeout_cmd || exit $EXIT_CONFIG_ERROR

    log_header "Running SPEED"
    log_info "Max parallel: ${max_parallel} | Model: ${model}"

    # Check for circular dependencies before starting
    if ! task_topo_sort > /dev/null; then
        log_error "Cannot run: circular dependencies in task graph. Fix depends_on fields."
        exit 1
    fi

    # Ensure working tree is committed so task branches see all files
    # Acquire main-branch lock since this does git add + commit on the shared tree
    if main_branch_acquire_lock "baseline"; then
        git_create_baseline
        main_branch_release_lock
    else
        log_warn "Could not acquire main-branch lock for baseline — proceeding (may miss uncommitted files)"
    fi

    # Verify tasks exist
    local total
    total=$(task_count_total)
    if [[ "$total" -eq 0 ]]; then
        log_error "No tasks found. Run 'speed plan <spec>' first."
        exit 1
    fi

    # Check for stale state — auto-recover if previous run was killed
    local current_state
    current_state=$(jq -r '.status // "idle"' "$STATE_FILE" 2>/dev/null || echo "idle")
    if [[ "$current_state" == "running" ]]; then
        log_warn "SPEED state is 'running' — previous run likely crashed. Auto-recovering..."

        # Kill any orphan agents still running from the crashed session
        local killed
        killed=$(_kill_orphan_agents)
        if [[ "$killed" -gt 0 ]]; then
            log_step "Killed ${killed} orphan agent process(es)"
        fi

        # Reset running tasks back to pending
        for f in "${TASKS_DIR}"/*.json; do
            [[ -f "$f" ]] || continue
            local status tid
            status=$(jq -r '.status' "$f")
            tid=$(jq -r '.id' "$f")
            if [[ "$status" == "running" ]]; then
                log_step "Resetting stale running task ${tid} to pending"
                task_reset_pending "$tid"
                git_remove_worktree "$tid"
            fi
        done

        # Clean stale tracking state
        rm -rf "${FEATURE_DIR}/running" "${FEATURE_DIR}/support"

        # Clean up orphaned worktrees
        git_cleanup_worktrees

        # Break stale locks
        speed_force_break_lock

        log_success "Auto-recovery complete — starting fresh"
    fi

    # Update state
    jq -n \
        --arg status "running" \
        --arg started "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
        '{status: $status, agents: [], started_at: $started, failure_history: []}' > "$STATE_FILE"

    # Detect the base branch all task branches fork from
    local main_branch
    main_branch=$(git_main_branch)

    # ── Agent tracking via files (bash 3 compatible) ───────────
    local running_dir="${FEATURE_DIR}/running"
    rm -rf "$running_dir"
    mkdir -p "$running_dir"

    _running_count() {
        local count=0
        for f in "$running_dir"/*.pid; do
            [[ -f "$f" ]] && ((count++))
        done
        echo "$count"
    }

    _running_task_ids() {
        for f in "$running_dir"/*.pid; do
            [[ -f "$f" ]] || continue
            basename "$f" .pid
        done
    }

    # ── Failure tracking for pattern detection ─────────────────
    local failure_log="${FEATURE_DIR}/failure_history.jsonl"
    > "$failure_log"  # Clear

    _record_failure() {
        local task_id="$1"
        local error="$2"
        jq -nc --arg tid "$task_id" --arg err "$error" --arg ts "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
            '{task_id: $tid, error: $err, timestamp: $ts}' >> "$failure_log"
    }

    _failure_count() {
        wc -l < "$failure_log" 2>/dev/null | tr -d ' '
    }

    # ── Support agent tracking (debugger, supervisor) ──────────
    # These run in the background so they don't freeze the loop.
    # Each file in support_dir stores: agent_type:task_id (e.g. "debugger:3")
    local support_dir="${FEATURE_DIR}/support"
    rm -rf "$support_dir"
    mkdir -p "$support_dir"

    _spawn_support_agent() {
        local agent_type="$1"   # "debugger" or "supervisor"
        local for_task_id="$2"
        local prompt_file="$3"
        local message="$4"
        local output_file="${LOGS_DIR}/${agent_type}-${for_task_id}-bg.log"

        local pid
        pid=$(claude_spawn_bg \
            "$prompt_file" \
            "$message" \
            "$output_file" \
            "$MODEL_SUPPORT" \
            "$AGENT_TOOLS_READONLY")

        echo "$pid" > "${support_dir}/${agent_type}-${for_task_id}.pid"
        echo "$for_task_id" > "${support_dir}/${agent_type}-${for_task_id}.task"
        log_step "Spawned ${COLOR_STEP}${agent_type}${RESET} for task ${for_task_id}"
        log_verbose "  PID: ${pid} | log: ${output_file}"
    }

    # ── Merge-conflict tracking (bash 3 compatible, file-based) ──
    local merge_attempts_dir="${FEATURE_DIR}/merge_attempts"
    rm -rf "$merge_attempts_dir"
    mkdir -p "$merge_attempts_dir"
    MERGE_CONFLICT_MAX_RETRIES=3

    _record_merge_attempt() {
        local tid="$1"
        local attempt_file="${merge_attempts_dir}/${tid}"
        local count=0
        if [[ -f "$attempt_file" ]]; then
            count=$(cat "$attempt_file")
        fi
        echo "$(( count + 1 ))" > "$attempt_file"
    }

    _get_merge_attempts() {
        local tid="$1"
        local attempt_file="${merge_attempts_dir}/${tid}"
        if [[ -f "$attempt_file" ]]; then
            cat "$attempt_file"
        else
            echo "0"
        fi
    }

    # ── Status line tracking ─────────────────────────────────────
    local _prev_status_counts=""

    # ── Main orchestration loop ──────────────────────────────────
    while true; do
        # Check for completed agents
        for pid_file in "$running_dir"/*.pid; do
            [[ -f "$pid_file" ]] || continue
            local task_id pid
            task_id=$(basename "$pid_file" .pid)
            pid=$(cat "$pid_file")

            # Check if done marker exists (agent finished) or process stopped
            local output_file="${LOGS_DIR}/${task_id}.log"
            local done_marker="${output_file}.done"

            if [[ -f "$done_marker" ]] || ! claude_is_running "$pid"; then
                # Wait briefly for file writes to flush
                sleep "$COMPLETION_FLUSH_WAIT"

                # ── Check for crash: process gone but no .done marker ──
                if [[ ! -f "$done_marker" ]] && ! claude_is_running "$pid"; then
                    log_error "Task ${task_id}: agent process disappeared without completion marker (crash/OOM/SIGKILL)"
                    task_set_failed "$task_id" "Agent process crashed (no completion marker)"
                    _record_failure "$task_id" "Agent process crashed"
                    rm -f "$pid_file"
                    git_remove_worktree "$task_id"
                    continue
                fi

                # ── Check for CLI error (auth failure, model not found, etc.) ──
                local error_marker="${output_file}.error"
                if [[ -f "$error_marker" ]]; then
                    local cli_exit_code
                    cli_exit_code=$(cat "$error_marker" 2>/dev/null || echo "?")
                    log_error "Task ${task_id}: Claude CLI error (exit code ${cli_exit_code})"
                    task_set_failed "$task_id" "Claude CLI error (exit code ${cli_exit_code})"
                    _record_failure "$task_id" "Claude CLI error (exit code ${cli_exit_code})"
                    rm -f "$pid_file" "$done_marker" "$error_marker"
                    git_remove_worktree "$task_id"
                    continue
                fi

                # ── Check for timeout (before blocked — timeouts are not blocked) ──
                local timeout_marker="${output_file}.timeout"
                if [[ -f "$timeout_marker" ]]; then
                    local timeout_count current_model
                    timeout_count=$(jq -r '.timeout_count // 0' "${TASKS_DIR}/${task_id}.json")
                    current_model=$(jq -r --arg def "$MODEL_SUPPORT" '.agent_model // $def' "${TASKS_DIR}/${task_id}.json")

                    task_set_timeout "$task_id" "Agent timed out after ${DEFAULT_AGENT_TIMEOUT}s"
                    rm -f "$pid_file" "$done_marker" "$timeout_marker"
                    git_remove_worktree "$task_id"

                    if [[ "$timeout_count" -eq 0 ]] && [[ "$current_model" != "opus" ]]; then
                        # First timeout on sonnet → escalate to opus
                        log_warn "Task ${task_id}: timed out on ${current_model} — escalating to opus and retrying"
                        task_update "$task_id" "agent_model" "opus"
                        task_reset_pending "$task_id"
                    else
                        # Already on opus or second timeout → human problem
                        log_error_block \
                            "Task ${task_id} timed out after ${DEFAULT_AGENT_TIMEOUT}s" \
                            "Agent exceeded time limit on ${current_model} (attempt $((timeout_count + 1)))" \
                            "speed retry --task-id ${task_id} --escalate"
                        _record_failure "$task_id" "Timeout after model escalation"
                    fi
                    continue
                fi

                # ── Check for blocked status ───────────────────────
                local blocked_json
                blocked_json=$(parse_agent_json "$(cat "$output_file")" 2>/dev/null) || blocked_json=""
                if [[ -n "$blocked_json" ]] && echo "$blocked_json" | jq -e '.status == "blocked"' &>/dev/null; then
                    log_warn "Task ${task_id}: agent reported BLOCKED"

                    local uncertain_about
                    uncertain_about=$(echo "$blocked_json" | jq -r '.uncertain_about // "Unknown"')
                    log_warn "  Uncertainty: ${uncertain_about}"

                    # Atomic: status + error + agent_pid in one write
                    task_set_blocked "$task_id" "$blocked_json"

                    # Invoke supervisor for blocked tasks
                    _invoke_supervisor "$task_id" "blocked"

                    rm -f "$pid_file" "$done_marker"
                    git_remove_worktree "$task_id"
                    continue
                fi

                # ── Normal completion check ───────────────────────
                # Resolve worktree path for this task
                local task_worktree="${WORKTREES_DIR}/task-${task_id}"

                if [[ -s "$output_file" ]]; then
                    log_success "Task ${task_id} agent completed"

                    if gates_run "$task_id" "$task_worktree"; then
                        # Atomic: status + completed_at + agent_pid in one write
                        task_set_done "$task_id"
                        log_success "Task ${task_id}: ${COLOR_SUCCESS}DONE${RESET}"

                        # Extract decisions and concerns from agent output
                        # so downstream dependent tasks can see what this agent learned
                        local completion_json
                        completion_json=$(parse_agent_json "$(cat "$output_file")" 2>/dev/null) || completion_json=""
                        if [[ -n "$completion_json" ]] && echo "$completion_json" | jq -e '.status == "done"' &>/dev/null; then
                            local has_metadata
                            has_metadata=$(echo "$completion_json" | jq 'has("decisions") or has("concerns")')
                            if [[ "$has_metadata" == "true" ]]; then
                                local tmp_task; tmp_task=$(mktemp)
                                jq --argjson dec "$(echo "$completion_json" | jq '.decisions // []')" \
                                   --argjson con "$(echo "$completion_json" | jq '.concerns // []')" \
                                    '.decisions = $dec | .concerns = $con' \
                                    "${TASKS_DIR}/${task_id}.json" > "$tmp_task" && mv "$tmp_task" "${TASKS_DIR}/${task_id}.json"
                            fi
                        fi

                        # Clean up worktree (frees the branch lock)
                        # NOTE: We do NOT merge into main here. Merging is deferred
                        # to just before spawning a dependent task, so in-flight agents
                        # are never disturbed by main moving underneath them.
                        git_remove_worktree "$task_id"
                    else
                        # Atomic: status + error + agent_pid in one write
                        task_set_failed "$task_id" "Quality gates failed"
                        log_error_block \
                            "Quality gates failed for task ${task_id}" \
                            "One or more quality checks did not pass" \
                            "Fix the issues and run: speed retry --task-id ${task_id}"
                        _record_failure "$task_id" "Quality gates failed"

                        # Keep worktree for debugger analysis
                        # (will be cleaned up on retry or recover)

                        # Invoke debugger for diagnosis
                        _invoke_debugger "$task_id"

                        # Check for pattern failures
                        local fail_count
                        fail_count=$(_failure_count)
                        if [[ "$fail_count" -ge "$PATTERN_FAILURE_THRESHOLD" ]]; then
                            log_warn "Multiple failures detected — invoking Supervisor for pattern analysis"
                            _invoke_supervisor "$task_id" "pattern"
                        fi
                    fi
                else
                    # Atomic: status + error + agent_pid in one write
                    task_set_failed "$task_id" "Agent produced no output"
                    log_error "Task ${task_id}: agent produced no output"
                    _record_failure "$task_id" "Agent produced no output"
                    git_remove_worktree "$task_id"
                fi

                # Clean up tracking
                rm -f "$pid_file" "$done_marker"
            fi
        done

        # ── Check for completed support agents (debugger/supervisor) ──
        for support_pid_file in "$support_dir"/*.pid; do
            [[ -f "$support_pid_file" ]] || continue
            local support_name support_pid support_output_file support_done_marker
            support_name=$(basename "$support_pid_file" .pid)
            support_pid=$(cat "$support_pid_file")
            support_output_file="${LOGS_DIR}/${support_name}-bg.log"
            support_done_marker="${support_output_file}.done"

            if [[ -f "$support_done_marker" ]] || ! kill -0 "$support_pid" 2>/dev/null; then
                sleep "$COMPLETION_FLUSH_WAIT"

                # Detect failure mode
                local support_error=""
                if [[ ! -f "$support_done_marker" ]] && ! kill -0 "$support_pid" 2>/dev/null; then
                    support_error="Agent process crashed (no completion marker)"
                elif [[ -f "${support_output_file}.timeout" ]]; then
                    support_error="Agent timed out after ${DEFAULT_AGENT_TIMEOUT}s"
                elif [[ -f "${support_output_file}.error" ]]; then
                    local cli_rc
                    cli_rc=$(cat "${support_output_file}.error" 2>/dev/null || echo "?")
                    support_error="Claude CLI error (exit code ${cli_rc})"
                fi

                # Parse agent_type and task_id from the name (e.g. "debugger-3" or "supervisor-pattern-3")
                local support_task_id support_agent_type
                support_task_id=$(cat "${support_dir}/${support_name}.task" 2>/dev/null || echo "")
                # Agent type is everything before the last -<task_id>
                support_agent_type="${support_name%-"${support_task_id}"}"

                if [[ -n "$support_task_id" ]] && [[ -n "$support_agent_type" ]]; then
                    _handle_support_completion "$support_agent_type" "$support_task_id" "$support_error"
                fi
                rm -f "$support_pid_file" "${support_dir}/${support_name}.task" \
                      "$support_done_marker" "${support_output_file}.timeout" "${support_output_file}.error"
            fi
        done

        # Count running agents
        local running_count
        running_count=$(_running_count)

        # Count running support agents (don't exit loop while they're active)
        local support_count=0
        for f in "$support_dir"/*.pid; do
            [[ -f "$f" ]] && ((support_count++))
        done

        # Find ready tasks and spawn agents
        local ready_tasks
        ready_tasks=$(_get_ready_tasks)

        if [[ -z "$ready_tasks" ]] && [[ $running_count -eq 0 ]]; then
            # Nothing ready and nothing running — check if blocked tasks exist
            local blocked_count
            blocked_count=$(task_count_by_status "blocked")
            if [[ "$blocked_count" -gt 0 ]]; then
                log_warn "${blocked_count} task(s) blocked — awaiting human input"
                log_warn "Run ${COLOR_STEP}speed status${RESET} for supervisor analysis"
            fi
            if [[ $support_count -gt 0 ]]; then
                log_info "${support_count} support agent(s) finishing in background — output in ${LOGS_DIR}/"
            fi
            break
        fi

        if [[ -n "$ready_tasks" ]]; then
            while IFS= read -r task_id; do
                if [[ $running_count -ge $max_parallel ]]; then
                    break
                fi

                # ── File conflict check ───────────────────────────
                local conflict_output
                conflict_output=$(grounding_check_file_conflicts "$task_id")
                if [[ $? -ne 0 ]] && [[ -n "$conflict_output" ]]; then
                    log_warn "Task ${task_id}: file conflict detected, deferring"
                    log_warn "  ${conflict_output}"
                    continue
                fi

                # Read task details
                local task_json
                task_json=$(task_get "$task_id")
                local title description criteria task_model branch
                title=$(echo "$task_json" | jq -r '.title')
                description=$(echo "$task_json" | jq -r '.description')
                criteria=$(echo "$task_json" | jq -r '.acceptance_criteria')
                task_model=$(echo "$task_json" | jq -r ".agent_model // \"${model}\"")
                branch=$(echo "$task_json" | jq -r '.branch')

                # Get files_touched for scope awareness
                local files_touched
                files_touched=$(echo "$task_json" | jq -r '.files_touched // [] | join(", ")')

                # Append review feedback if retrying
                local feedback
                feedback=$(echo "$task_json" | jq -r '.review_feedback // empty')
                local extra_context=""
                if [[ -n "$feedback" ]]; then
                    extra_context=$'\n\n## Previous Review Feedback\n\n'"${feedback}"
                fi

                # Append debugger analysis if retrying after failure
                local debugger_log="${LOGS_DIR}/debugger-${task_id}.json"
                if [[ -f "$debugger_log" ]]; then
                    extra_context+=$'\n\n## Debugger Analysis (from previous failure)\n\n'"$(cat "$debugger_log")"
                fi

                # Gather decisions and concerns from completed dependencies
                # so this agent knows what upstream agents learned and flagged
                local upstream_context=""
                local dep_ids_for_context
                dep_ids_for_context=$(echo "$task_json" | jq -r '.depends_on[]?' 2>/dev/null)
                if [[ -n "$dep_ids_for_context" ]]; then
                    while IFS= read -r dep_id; do
                        [[ -z "$dep_id" ]] && continue
                        local dep_file="${TASKS_DIR}/${dep_id}.json"
                        [[ -f "$dep_file" ]] || continue
                        local dep_title dep_decisions dep_concerns
                        dep_title=$(jq -r '.title' "$dep_file")
                        dep_decisions=$(jq -r '.decisions // [] | if length > 0 then map("  - " + .) | join("\n") else empty end' "$dep_file")
                        dep_concerns=$(jq -r '.concerns // [] | if length > 0 then map("  - " + .) | join("\n") else empty end' "$dep_file")
                        if [[ -n "$dep_decisions" ]] || [[ -n "$dep_concerns" ]]; then
                            upstream_context+=$'\n'"#### Task ${dep_id}: ${dep_title}"
                            if [[ -n "$dep_decisions" ]]; then
                                upstream_context+=$'\n'"Decisions:"$'\n'"${dep_decisions}"
                            fi
                            if [[ -n "$dep_concerns" ]]; then
                                upstream_context+=$'\n'"Concerns:"$'\n'"${dep_concerns}"
                            fi
                        fi
                    done <<< "$dep_ids_for_context"
                fi
                if [[ -n "$upstream_context" ]]; then
                    extra_context+=$'\n\n## Context from Completed Dependencies\n'"${upstream_context}"
                fi

                # ── Deferred dependency merge ────────────────────
                # Merge completed dependency branches into main NOW, right
                # before creating this task's worktree. This ensures the new
                # worktree sees all predecessor work without ever disturbing
                # agents that are already running in their own worktrees.
                #
                # The main-branch lock serializes merges across parallel
                # features so two orchestrators never do checkout+merge
                # on the shared working tree simultaneously.
                local dep_ids
                dep_ids=$(echo "$task_json" | jq -r '.depends_on[]?' 2>/dev/null)
                if [[ -n "$dep_ids" ]]; then
                    local merge_failed=false

                    if ! main_branch_acquire_lock "deferred-merge/task-${task_id}"; then
                        log_warn "Task ${task_id}: could not acquire main-branch lock — deferring"
                        continue
                    fi

                    while IFS= read -r dep_id; do
                        [[ -z "$dep_id" ]] && continue
                        local dep_branch
                        dep_branch=$(jq -r '.branch // empty' "${TASKS_DIR}/${dep_id}.json" 2>/dev/null)
                        [[ -z "$dep_branch" || "$dep_branch" == "null" ]] && continue
                        git_branch_exists "$dep_branch" || continue

                        # Skip if already merged into main
                        if _git merge-base --is-ancestor "$dep_branch" "$main_branch" 2>/dev/null; then
                            continue
                        fi

                        log_step "Deferred merge: ${dep_branch} → ${main_branch} (dependency of task ${task_id})"
                        if git_safe_merge "$dep_branch" "$main_branch"; then
                            log_success "Merged ${dep_branch} into ${main_branch}"
                        else
                            _record_merge_attempt "$task_id"
                            local attempts
                            attempts=$(_get_merge_attempts "$task_id")
                            if [[ "$attempts" -ge "$MERGE_CONFLICT_MAX_RETRIES" ]]; then
                                log_error_block \
                                    "Cannot merge ${dep_branch} into ${main_branch}" \
                                    "Conflicting changes persisted after ${attempts} attempts" \
                                    "Resolve manually, then: speed integrate --continue"
                                task_set_blocked "$task_id" "Merge conflict: ${dep_branch} into ${main_branch} (failed ${attempts}x)"
                                _record_failure "$task_id" "Persistent merge conflict: ${dep_branch}"
                            else
                                log_warn "Deferred merge failed for ${dep_branch} — deferring task ${task_id} (attempt ${attempts}/${MERGE_CONFLICT_MAX_RETRIES})"
                            fi
                            merge_failed=true
                            break
                        fi
                    done <<< "$dep_ids"

                    main_branch_release_lock

                    if $merge_failed; then
                        continue  # skip this task, try again next loop iteration
                    fi
                fi

                # Create isolated worktree for this agent
                local worktree_path
                worktree_path=$(git_create_worktree "$task_id" "$branch")
                git_setup_worktree_deps "$worktree_path"

                # Build agent message
                local files_section=""
                if [[ -n "$files_touched" ]]; then
                    files_section="
### Declared Files (stay within scope)
${files_touched}"
                fi

                local agent_message="## Task: ${title}

### Description
${description}

### Acceptance Criteria
${criteria}
${files_section}

### Git Branch
You are working on branch: \`${branch}\`
You are already on this branch in an isolated worktree. Do NOT run git checkout.
Commit your work to this branch.${extra_context}

### Quality Checks
Run gates iteratively as you work:
- After each group of files: \`./speed/speed gates -f ${FEATURE_NAME} --task ${task_id} --fast\`
- Before declaring done: \`./speed/speed gates -f ${FEATURE_NAME} --task ${task_id} --full\`
All gates must pass before you output your completion JSON.

### Working Directory
${worktree_path}"

                # Spawn agent in the worktree directory
                local output_file="${LOGS_DIR}/${task_id}.log"
                local pid
                pid=$(claude_spawn_bg \
                    "${AGENTS_DIR}/developer.md" \
                    "$agent_message" \
                    "$output_file" \
                    "$task_model" \
                    "$AGENT_TOOLS_FULL" \
                    "$worktree_path")

                echo "$pid" > "${running_dir}/${task_id}.pid"

                # Atomic: status + started_at + agent_pid in one write
                task_set_running "$task_id" "$pid"
                ((running_count++))

                log_step "Spawned agent for task ${task_id}: ${COLOR_STEP}${title}${RESET}"
                log_verbose "  PID: ${pid} | model: ${task_model} | branch: ${branch}"

                # Update state file
                jq --arg tid "$task_id" --arg pid "$pid" \
                    '.agents += [{"task_id": $tid, "pid": ($pid | tonumber)}]' \
                    "$STATE_FILE" > "${STATE_FILE}.tmp" && mv "${STATE_FILE}.tmp" "$STATE_FILE"

            done <<< "$ready_tasks"
        fi

        # Brief status update
        local done_count pending_count failed_count blocked_count
        done_count=$(task_count_by_status "done")
        running_count=$(_running_count)
        pending_count=$(task_count_by_status "pending")
        failed_count=$(task_count_by_status "failed")
        blocked_count=$(task_count_by_status "blocked")
        local elapsed=$((SECONDS - run_start))
        local elapsed_fmt
        elapsed_fmt=$(format_duration "$elapsed")
        if [[ "${VERBOSITY:-1}" -ge 1 ]]; then
            local support_suffix=""
            if [[ "$support_count" -gt 0 ]]; then
                support_suffix="  ${COLOR_DIM}(+${support_count} support)${RESET}"
            fi
            local status_line="${COLOR_STEP}${SYM_ARROW}${RESET} Running: ${running_count} of ${total} tasks  |  ${COLOR_SUCCESS}${SYM_CHECK}${RESET} ${done_count} done  ${SYM_PENDING} ${pending_count} pending  ${COLOR_ERROR}${SYM_CROSS}${RESET} ${failed_count} failed${support_suffix}  ${COLOR_DIM}[${elapsed_fmt}]${RESET}"
            local status_counts="${running_count}:${done_count}:${pending_count}:${failed_count}:${support_count}"

            if [[ -t 2 ]]; then
                # TTY: overwrite in place on stderr, clear to end of line
                echo -ne "\r\033[K${COLOR_DIM}[$(_log_timestamp)]${RESET} ${status_line}" >&2
            elif [[ "$status_counts" != "$_prev_status_counts" ]]; then
                # Non-TTY: print only when counts change, with newline
                echo -e "${COLOR_DIM}[$(_log_timestamp)]${RESET} ${status_line}" >&2
            fi
            _prev_status_counts="$status_counts"
        fi

        # Check halt threshold
        local fail_pct=0
        if [[ "$total" -gt 0 ]]; then
            fail_pct=$(( (failed_count * 100) / total ))
        fi
        if [[ "$fail_pct" -ge "$HALT_FAILURE_PCT" ]]; then
            echo ""
            log_error_block \
                "Over ${HALT_FAILURE_PCT}% of tasks failed (${failed_count}/${total}) — halting SPEED" \
                "Too many tasks are failing, indicating a systemic issue" \
                "Run: speed status  — then fix the root cause and: speed retry"
            break
        fi

        # Sleep before next check
        sleep "$POLL_INTERVAL"
    done

    # Clear the status line before final output
    if [[ -t 2 ]]; then
        echo -ne "\r\033[K" >&2
    fi
    echo ""

    # Clean up
    rm -rf "$running_dir" "$merge_attempts_dir" "$support_dir"

    # Final state update
    jq '.status = "idle" | .agents = []' "$STATE_FILE" > "${STATE_FILE}.tmp" && mv "${STATE_FILE}.tmp" "$STATE_FILE"

    # ── Compute final stats ──────────────────────────────────────
    local final_done final_failed final_blocked final_pending
    final_done=$(task_count_by_status "done")
    final_failed=$(task_count_by_status "failed")
    final_blocked=$(task_count_by_status "blocked")
    final_pending=$(task_count_by_status "pending")
    local elapsed=$((SECONDS - run_start))
    local elapsed_fmt
    elapsed_fmt=$(format_duration "$elapsed")

    # ── Determine exit code ──────────────────────────────────────
    local run_exit=$EXIT_OK
    if [[ "$final_failed" -gt 0 ]]; then
        local fail_pct_final=0
        if [[ "$total" -gt 0 ]]; then
            fail_pct_final=$(( (final_failed * 100) / total ))
        fi
        if [[ "$fail_pct_final" -ge "$HALT_FAILURE_PCT" ]]; then
            run_exit=$EXIT_HALTED
        else
            run_exit=$EXIT_TASK_FAILURE
        fi
    fi

    # ── JSON output mode ─────────────────────────────────────────
    if [[ "$JSON_OUTPUT" == "true" ]]; then
        local status_str="completed"
        [[ $run_exit -ne 0 ]] && status_str="failed"

        # Build failures array
        local failures_json="[]"
        if [[ "$final_failed" -gt 0 ]]; then
            failures_json=$(
                for f in "${TASKS_DIR}"/*.json; do
                    [[ -f "$f" ]] || continue
                    local s
                    s=$(jq -r '.status' "$f")
                    [[ "$s" == "failed" ]] && jq -c '{task_id: .id, title: .title, error: (.error // "unknown")}' "$f"
                done | jq -sc '.'
            )
        fi

        jq -nc \
            --arg status "$status_str" \
            --argjson tasks_total "$total" \
            --argjson tasks_passed "$final_done" \
            --argjson tasks_failed "$final_failed" \
            --argjson duration_seconds "$elapsed" \
            --argjson exit_code "$run_exit" \
            --argjson failures "$failures_json" \
            '{status: $status, tasks_total: $tasks_total, tasks_passed: $tasks_passed, tasks_failed: $tasks_failed, duration_seconds: $duration_seconds, exit_code: $exit_code, failures: $failures}'
        exit "$run_exit"
    fi

    # ── Print run summary ────────────────────────────────────────
    log_header "Run Summary"
    echo ""
    echo -e "  Total tasks:  ${total}"
    echo -e "  Passed:       ${final_done}   ${COLOR_SUCCESS}${SYM_CHECK}${RESET}"
    if [[ "$final_failed" -gt 0 ]]; then
        echo -e "  Failed:       ${final_failed}   ${COLOR_ERROR}${SYM_CROSS}${RESET}"
    else
        echo -e "  Failed:       0"
    fi
    if [[ "$final_blocked" -gt 0 ]]; then
        echo -e "  Blocked:      ${final_blocked}   ${COLOR_WARN}${SYM_WARN}${RESET}"
    fi
    if [[ "$final_pending" -gt 0 ]]; then
        echo -e "  Pending:      ${final_pending}   ${SYM_PENDING}"
    fi
    echo -e "  Duration:     ${elapsed_fmt}"
    echo ""

    # Show failed task details
    if [[ "$final_failed" -gt 0 ]]; then
        echo -e "  ${COLOR_ERROR}Failed tasks:${RESET}"
        for f in "${TASKS_DIR}"/*.json; do
            [[ -f "$f" ]] || continue
            local s tid ttitle terror
            s=$(jq -r '.status' "$f")
            [[ "$s" == "failed" ]] || continue
            tid=$(jq -r '.id' "$f")
            ttitle=$(jq -r '.title' "$f")
            terror=$(jq -r '.error // "unknown"' "$f")
            echo -e "    Task ${tid}: ${COLOR_DIM}\"${ttitle}\"${RESET}"
            echo -e "      Error: ${terror}"
            echo -e "      Fix:   ${COLOR_STEP}speed retry --task-id ${tid}${RESET}"
        done
        echo ""
    fi

    echo -e "${COLOR_DIM}$(printf '─%.0s' $(seq 1 50))${RESET}"
    echo ""

    # Task graph and summary
    task_print_graph
    echo ""
    task_print_summary
    echo ""

    if [[ "$final_failed" -gt 0 ]]; then
        log_warn "${final_failed} task(s) failed. Diagnose with ${COLOR_STEP}speed retry --task-id ID${RESET} then provide guidance with ${COLOR_STEP}--context${RESET}."
    fi

    if [[ "$final_blocked" -gt 0 ]]; then
        log_warn "${final_blocked} task(s) blocked. Run ${COLOR_STEP}speed status${RESET} for details and supervisor analysis."
    fi

    if [[ "$final_done" -gt 0 ]]; then
        echo -e "Next: ${COLOR_STEP}./speed/speed review${RESET} then ${COLOR_STEP}./speed/speed coherence${RESET} then ${COLOR_STEP}./speed/speed integrate${RESET}"
    fi
    echo ""
    log_result "Completed in ${elapsed_fmt}"

    exit "$run_exit"
}

# ── Get ready tasks: pending + deps met + not blocked ────────

_get_ready_tasks() {
    _ensure_jq
    local pending
    pending=$(task_list_by_status "pending")

    if [[ -z "$pending" ]]; then
        return
    fi

    while IFS= read -r id; do
        if task_deps_met "$id"; then
            echo "$id"
        fi
    done <<< "$pending"
}

# ── Invoke debugger on a failed task ─────────────────────────

_invoke_debugger() {
    local task_id="$1"
    local task_json
    task_json=$(task_get "$task_id")
    local title description criteria branch
    title=$(echo "$task_json" | jq -r '.title')
    description=$(echo "$task_json" | jq -r '.description')
    criteria=$(echo "$task_json" | jq -r '.acceptance_criteria')
    branch=$(echo "$task_json" | jq -r '.branch')

    local output_file="${LOGS_DIR}/${task_id}.log"
    local agent_output=""
    if [[ -f "$output_file" ]]; then
        local total_lines
        total_lines=$(wc -l < "$output_file" | tr -d ' ')
        if [[ "$total_lines" -le "$AGENT_OUTPUT_TAIL" ]]; then
            agent_output=$(cat "$output_file")
        else
            local half=$(( AGENT_OUTPUT_TAIL / 2 ))
            local omitted=$(( total_lines - AGENT_OUTPUT_TAIL ))
            agent_output=$(head -"$half" "$output_file")
            agent_output+=$'\n'"... ${omitted} lines omitted ..."$'\n'
            agent_output+=$(tail -"$half" "$output_file")
        fi
    fi

    local diff=""
    if git_branch_exists "$branch" 2>/dev/null; then
        diff=$(_git diff "$(git_main_branch)...${branch}" 2>/dev/null | head -"$DIFF_HEAD_LINES" || echo "No diff")
    fi

    local debugger_message="## Failed Task ${task_id}: ${title}

### Task Description
${description}

### Acceptance Criteria
${criteria}

### Agent Output
${agent_output}

### Git Diff (first 500 lines)
\`\`\`diff
${diff}
\`\`\`

Diagnose why this task failed and provide a specific fix."

    _spawn_support_agent "debugger" "$task_id" "${AGENTS_DIR}/debugger.md" "$debugger_message"
}

# ── Invoke supervisor for diagnosis ──────────────────────────

_invoke_supervisor() {
    local task_id="$1"
    local trigger_type="$2"  # "blocked", "pattern", "coherence", "contract"

    local task_json
    task_json=$(task_get "$task_id")

    # Gather SPEED state
    local speed_state=""
    speed_state+="Total tasks: $(task_count_total)\n"
    speed_state+="Done: $(task_count_by_status "done")\n"
    speed_state+="Running: $(task_count_by_status "running")\n"
    speed_state+="Pending: $(task_count_by_status "pending")\n"
    speed_state+="Failed: $(task_count_by_status "failed")\n"
    speed_state+="Blocked: $(task_count_by_status "blocked")\n"

    # Gather failure history
    local failure_history=""
    local failure_log="${FEATURE_DIR}/failure_history.jsonl"
    if [[ -f "$failure_log" ]]; then
        failure_history=$(cat "$failure_log")
    fi

    # Gather task details
    local task_details=""
    task_details+="Task ${task_id}: $(echo "$task_json" | jq -r '.title')\n"
    task_details+="Status: $(echo "$task_json" | jq -r '.status')\n"
    task_details+="Error: $(echo "$task_json" | jq -r '.error // "none"')\n"

    # Include debugger analysis if available
    local debugger_log="${LOGS_DIR}/debugger-${task_id}.json"
    if [[ -f "$debugger_log" ]]; then
        task_details+="\nDebugger Analysis:\n$(cat "$debugger_log")\n"
    fi

    local supervisor_message="## Supervisor Trigger: ${trigger_type}

### SPEED State
$(echo -e "$speed_state")

### Triggering Task
$(echo -e "$task_details")

### Failure History
${failure_history}

Diagnose the situation and recommend recovery actions."

    _spawn_support_agent "supervisor-${trigger_type}" "$task_id" "${AGENTS_DIR}/supervisor.md" "$supervisor_message"
}

# ── Process completed support agent output ────────────────────
# Called from the polling loop when a debugger/supervisor finishes.

_handle_support_completion() {
    local agent_type="$1"  # e.g. "debugger" or "supervisor-pattern"
    local for_task_id="$2"
    local error="${3:-}"    # non-empty if agent crashed/timed out/CLI error
    local output_file="${LOGS_DIR}/${agent_type}-${for_task_id}-bg.log"

    # Build the parsed result, with fallback error JSON on any failure
    local parsed=""
    if [[ -n "$error" ]]; then
        log_warn "${agent_type} for task ${for_task_id}: ${error}"
        parsed="{\"error\": \"${agent_type} failed: ${error}\"}"
    elif [[ ! -s "$output_file" ]]; then
        log_warn "${agent_type} for task ${for_task_id} produced no output"
        parsed="{\"error\": \"${agent_type} returned empty output\"}"
    else
        local raw_output
        raw_output=$(cat "$output_file")
        parsed=$(parse_agent_json "$raw_output") || parsed="$raw_output"
    fi

    if [[ "$agent_type" == "debugger" ]]; then
        # Always write the file so retry path has something to read
        echo "$parsed" > "${LOGS_DIR}/debugger-${for_task_id}.json"
        if [[ -n "$error" ]]; then
            log_warn "Debugger failed for task ${for_task_id} — retry will proceed without analysis"
        else
            log_step "Debugger analysis saved to ${LOGS_DIR}/debugger-${for_task_id}.json"
        fi
    elif [[ "$agent_type" == supervisor-* ]]; then
        local supervisor_log="${LOGS_DIR}/supervisor-${for_task_id}-$(date +%s).json"
        echo "$parsed" > "$supervisor_log"
        _prune_logs "supervisor-${for_task_id}-" ".json"

        if ! _require_json "Supervisor" "$parsed"; then
            log_warn "Skipping supervisor analysis — see ${supervisor_log}"
            echo ""
            log_step "Full analysis: ${supervisor_log}"
            return 0
        fi

        # Surface diagnosis
        local diagnosis
        diagnosis=$(echo "$parsed" | jq -r '.diagnosis // empty')
        if [[ -n "$diagnosis" ]]; then
            echo ""
            echo -e "${BOLD}Supervisor Diagnosis:${RESET}"
            echo -e "  ${diagnosis}"
        fi

        # Surface pattern detection
        local pattern_desc
        pattern_desc=$(echo "$parsed" | jq -r '.pattern_detected.description // empty')
        if [[ -n "$pattern_desc" ]]; then
            local root_cause affected
            root_cause=$(echo "$parsed" | jq -r '.pattern_detected.root_cause // "Unknown"')
            affected=$(echo "$parsed" | jq -r '.pattern_detected.affected_tasks // [] | join(", ")')
            echo ""
            echo -e "${COLOR_ERROR}${BOLD}PATTERN DETECTED:${RESET} ${pattern_desc}"
            echo -e "  ${BOLD}Root cause:${RESET} ${root_cause}"
            echo -e "  ${BOLD}Affected tasks:${RESET} ${affected}"
        fi

        # Surface recommendations
        local action_count
        action_count=$(echo "$parsed" | jq '[.actions // [] | .[]] | length')
        if [[ "$action_count" -gt 0 ]]; then
            echo ""
            echo -e "${BOLD}Supervisor Recommendations:${RESET}"
            echo "$parsed" | jq -r '
                .actions[]? |
                "  \(.action) task \(.task_id // "?"): \(.reason // "no reason given")" +
                if .human_question then "\n    → HUMAN INPUT: \(.human_question)" else "" end +
                if .additional_context then "\n    → Context: \(.additional_context)" else "" end
            '
        fi

        local rec_count
        rec_count=$(echo "$parsed" | jq '[.recommendations // [] | .[]] | length')
        if [[ "$rec_count" -gt 0 ]]; then
            echo ""
            echo -e "${BOLD}Suggestions:${RESET}"
            echo "$parsed" | jq -r '.recommendations[]? | "  • \(.)"'
        fi

        # Check halt recommendation
        local should_halt
        should_halt=$(echo "$parsed" | jq -r '.should_halt // false')
        if [[ "$should_halt" == "true" ]]; then
            local halt_reason
            halt_reason=$(echo "$parsed" | jq -r '.halt_reason // "Unknown"')
            echo ""
            log_error "Supervisor recommends HALTING: ${halt_reason}"
        fi

        echo ""
        log_step "Full analysis: ${supervisor_log}"
    fi
}

# ── Product Guardian: vision alignment check ──────────────────
# Runs the Product Guardian agent against any input (spec, diff, integration)
# Returns: 0 = aligned, 1 = rejected, 2 = flagged (warnings)
_run_guardian() {
    local check_type="$1"  # "pre-plan" | "post-review" | "post-integration"
    local content="$2"
    local label="${3:-}"

    local overview_file="${PROJECT_ROOT}/${VISION_FILE}"
    if [[ ! -f "$overview_file" ]]; then
        log_warn "Product overview not found at ${overview_file} — skipping guardian check"
        return 0
    fi

    local overview_content
    overview_content=$(cat "$overview_file")

    local guardian_message="## Guardian Check: ${check_type}

### Product Vision (source of truth)
${overview_content}

### Input to Evaluate
${content}

Evaluate this ${check_type} input against the product vision. Respond with JSON."

    log_step "Running Product Guardian (${check_type})..."

    local raw_guardian_output
    if ! raw_guardian_output=$(claude_run \
        "${AGENTS_DIR}/product-guardian.md" \
        "$guardian_message" \
        "$MODEL_SUPPORT" \
        "$AGENT_TOOLS_READONLY" \
        "Guardian"); then
        log_warn "Guardian agent failed (${check_type}) — check Claude CLI connection"
        return 3
    fi

    if [[ -z "$raw_guardian_output" ]]; then
        log_warn "Guardian agent returned empty output (${check_type})"
        return 3
    fi

    local guardian_output
    guardian_output=$(parse_agent_json "$raw_guardian_output") || guardian_output="$raw_guardian_output"

    # Save report
    local timestamp
    timestamp=$(date +%s)
    local log_file="${LOGS_DIR}/guardian-${check_type}-${timestamp}.json"
    echo "$guardian_output" > "$log_file"
    _prune_logs "guardian-${check_type}-" ".json"

    # Parse status — if invalid JSON, falls through to the * case
    if ! _require_json "Guardian" "$guardian_output"; then
        log_warn "Review raw output: ${log_file}"
    fi

    local status
    status=$(echo "$guardian_output" | jq -r '.status // "unknown"' 2>/dev/null || echo "unknown")
    local summary
    summary=$(echo "$guardian_output" | jq -r '.summary // "No summary"' 2>/dev/null || echo "No summary")

    case "$status" in
        aligned)
            log_success "Guardian: ${COLOR_SUCCESS}ALIGNED${RESET} — ${summary}"
            echo "$guardian_output"
            return 0
            ;;
        flagged)
            log_warn "Guardian: ${COLOR_WARN}FLAGGED${RESET} — ${summary}"
            echo "$guardian_output"

            # Print flags
            local flag_count
            flag_count=$(echo "$guardian_output" | jq '.flags | length')
            if [[ "$flag_count" -gt 0 ]]; then
                echo ""
                echo -e "  ${BOLD}Vision Flags:${RESET}"
                echo "$guardian_output" | jq -r '.flags[] | "    \(.severity): \(.description)"'
                echo ""
            fi
            return 2
            ;;
        rejected)
            log_error "Guardian: ${COLOR_ERROR}REJECTED${RESET} — ${summary}"
            echo "$guardian_output"

            # Print critical flags
            local critical_flags
            critical_flags=$(echo "$guardian_output" | jq -r '.flags[] | select(.severity == "critical") | "    \(.description)\n    Spec: \(.vision_reference // .spec_reference)"' 2>/dev/null || echo "")
            if [[ -n "$critical_flags" ]]; then
                echo ""
                echo -e "  ${BOLD}Critical Violations:${RESET}"
                echo -e "$critical_flags"
                echo ""
            fi

            # Print Won't Have violations
            local wont_have
            wont_have=$(echo "$guardian_output" | jq -r '(.scope_violations // .wont_have_violations // [])[] | "    \(.feature) → maps to Won'\''t Have: \(.maps_to)"' 2>/dev/null || echo "")
            if [[ -n "$wont_have" ]]; then
                echo -e "  ${BOLD}Won't Have Violations:${RESET}"
                echo -e "$wont_have"
                echo ""
            fi
            return 1
            ;;
        *)
            log_warn "Guardian returned unparseable status '${status}'. Review: ${log_file}"
            log_warn "This may indicate the guardian agent failed or returned non-JSON output."
            # Show first 3 lines for quick diagnosis
            echo "$guardian_output" | head -3 | while IFS= read -r line; do
                echo -e "    ${COLOR_DIM}${line}${RESET}" >&2
            done
            echo "$guardian_output"
            return 3  # Distinct code: 0=aligned, 1=rejected, 2=flagged, 3=unparseable
            ;;
    esac
}

# Standalone guardian command
cmd_guardian() {
    local input_file="${1:-}"

    log_header "Product Guardian"

    # If a file is provided, evaluate it (ad-hoc — no feature needed)
    if [[ -n "$input_file" ]]; then
        if [[ ! -f "$input_file" ]]; then
            if [[ -f "${PROJECT_ROOT}/${input_file}" ]]; then
                input_file="${PROJECT_ROOT}/${input_file}"
            else
                log_error "File not found: $input_file"
                exit 1
            fi
        fi

        # Use feature context for log output if available, else default LOGS_DIR
        feature_resolve "$GLOBAL_FEATURE" &>/dev/null && _require_feature "$GLOBAL_FEATURE" || mkdir -p "$LOGS_DIR"

        log_step "Evaluating: ${COLOR_STEP}${input_file}${RESET}"
        local content
        content=$(cat "$input_file")

        _run_guardian "ad-hoc" "$content" "$input_file"
        local rc=$?

        echo ""
        echo -e "Report saved to ${COLOR_STEP}${LOGS_DIR}/guardian-ad-hoc-*.json${RESET}"
        echo ""
        return $rc
    fi

    # No file — evaluate the current task plan + completed work (requires feature)
    _require_feature "$GLOBAL_FEATURE"

    local spec_file
    spec_file=$(_get_spec_path)
    if [[ -z "$spec_file" ]] || [[ ! -f "$spec_file" ]]; then
        log_error "No spec file found. Provide a file or run 'speed plan' first."
        log_error "Usage: speed guardian <spec-or-plan-file>"
        exit 1
    fi

    log_step "Evaluating current spec: ${COLOR_STEP}${spec_file}${RESET}"
    local content
    content=$(cat "$spec_file")

    # Include task plan if it exists
    local total
    total=$(task_count_total 2>/dev/null || echo "0")
    if [[ "$total" -gt 0 ]]; then
        content+="\n\n## Current Task Plan\n"
        for f in "${TASKS_DIR}"/*.json; do
            [[ -f "$f" ]] || continue
            local id title status
            id=$(jq -r '.id' "$f")
            title=$(jq -r '.title' "$f")
            status=$(jq -r '.status' "$f")
            content+="- Task ${id}: ${title} [${status}]\n"
        done
    fi

    _run_guardian "ad-hoc" "$content" "$spec_file"
    local rc=$?

    echo ""
    echo -e "Report saved to ${COLOR_STEP}${LOGS_DIR}/guardian-ad-hoc-*.json${RESET}"
    echo ""
    return $rc
}

cmd_status() {
    log_header "SPEED Status"

    # ── Feature overview ──────────────────────────────────────────
    local features
    features=$(feature_list)
    local active_feature
    active_feature=$(feature_get_active)

    if [[ -z "$features" ]]; then
        log_info "No features planned. Run 'speed plan <spec>' to start."
        return
    fi

    echo -e "${BOLD}Features:${RESET}"
    while IFS= read -r feat; do
        [[ -z "$feat" ]] && continue
        local feat_dir="${FEATURES_DIR}/${feat}"
        local feat_done=0 feat_total=0 feat_running=0 feat_failed=0
        for f in "${feat_dir}/tasks/"*.json; do
            [[ -f "$f" ]] || continue
            ((feat_total++))
            local s
            s=$(jq -r '.status // "unknown"' "$f")
            case "$s" in
                done) ((feat_done++)) ;;
                running) ((feat_running++)) ;;
                failed) ((feat_failed++)) ;;
            esac
        done
        local marker=""
        if [[ "$feat" == "$active_feature" ]]; then
            marker=" ${COLOR_SUCCESS}(active)${RESET}"
        fi
        local progress="${feat_done}/${feat_total}"
        local detail=""
        if [[ $feat_running -gt 0 ]]; then detail+=", ${COLOR_WARN}${feat_running} running${RESET}"; fi
        if [[ $feat_failed -gt 0 ]]; then detail+=", ${COLOR_ERROR}${feat_failed} failed${RESET}"; fi
        echo -e "  ${COLOR_STEP}${feat}${RESET}${marker} — ${progress} done${detail}"
    done <<< "$features"
    echo ""

    # ── Detailed view for the target feature ──────────────────────
    # If --feature is specified, show that one. Otherwise show the active feature.
    local target_feature=""
    if [[ -n "$GLOBAL_FEATURE" ]]; then
        target_feature="$GLOBAL_FEATURE"
    elif [[ -n "$active_feature" ]] && [[ -d "${FEATURES_DIR}/${active_feature}" ]]; then
        target_feature="$active_feature"
    else
        # Show first feature if only one exists
        local feat_count
        feat_count=$(echo "$features" | wc -l | tr -d ' ')
        if [[ "$feat_count" -eq 1 ]]; then
            target_feature="$features"
        else
            echo -e "Use ${COLOR_STEP}--feature <name>${RESET} to see details for a specific feature."
            echo ""
            return
        fi
    fi

    feature_activate "$target_feature"
    echo -e "${BOLD}Showing: ${COLOR_STEP}${target_feature}${RESET}"
    echo ""

    # Check if initialized
    if [[ ! -d "$TASKS_DIR" ]]; then
        log_info "Feature '${target_feature}' has no tasks."
        return
    fi

    local total
    total=$(task_count_total)

    if [[ "$total" -eq 0 ]]; then
        log_info "No tasks. Run 'speed plan <spec>' to create tasks."
        return
    fi

    # Task graph
    task_print_graph
    echo ""
    task_print_summary
    echo ""

    # State info
    if [[ -f "$STATE_FILE" ]]; then
        local speed_status
        speed_status=$(jq -r '.status' "$STATE_FILE")
        local agent_count
        agent_count=$(jq '.agents | length' "$STATE_FILE")

        echo -e "${BOLD}SPEED:${RESET} ${speed_status} | Active agents: ${agent_count}"

        if [[ "$agent_count" -gt 0 ]]; then
            echo -e "${BOLD}Active Agents:${RESET}"
            jq -r '.agents[] | "  PID \(.pid) → Task \(.task_id)"' "$STATE_FILE"
        fi
    fi

    # Contract info
    if [[ -f "${CONTRACT_FILE}" ]]; then
        echo -e "${BOLD}Contract:${RESET} ${COLOR_SUCCESS}present${RESET}"
    else
        echo -e "${BOLD}Contract:${RESET} ${COLOR_WARN}missing${RESET}"
    fi

    # Blocked tasks
    local blocked_count
    blocked_count=$(task_count_by_status "blocked")
    if [[ "$blocked_count" -gt 0 ]]; then
        echo ""
        echo -e "${BOLD}Blocked Tasks (need human input):${RESET}"
        for f in "${TASKS_DIR}"/*.json; do
            [[ -f "$f" ]] || continue
            local status
            status=$(jq -r '.status' "$f")
            if [[ "$status" == "blocked" ]]; then
                local id title error
                id=$(jq -r '.id' "$f")
                title=$(jq -r '.title' "$f")
                error=$(jq -r '.error // "No details"' "$f")
                echo -e "  ${COLOR_WARN}${SYM_WARN}${RESET} Task ${id}: ${title}"
                echo -e "    ${COLOR_DIM}${error}${RESET}"
            fi
        done
    fi

    # Timed-out tasks (failed after timeout escalation — need decomposition)
    local has_timeouts=false
    for f in "${TASKS_DIR}"/*.json; do
        [[ -f "$f" ]] || continue
        local tc
        tc=$(jq -r '.timeout_count // 0' "$f")
        if [[ "$tc" -gt 0 ]]; then
            if ! $has_timeouts; then
                echo ""
                echo -e "${BOLD}Timed-Out Tasks (consider decomposing):${RESET}"
                has_timeouts=true
            fi
            local id title model tc_val status
            id=$(jq -r '.id' "$f")
            title=$(jq -r '.title' "$f")
            model=$(jq -r --arg def "$MODEL_SUPPORT" '.agent_model // $def' "$f")
            tc_val=$(jq -r '.timeout_count' "$f")
            status=$(jq -r '.status' "$f")
            echo -e "  ${COLOR_WARN}${SYM_WARN}${RESET} Task ${id}: ${title} ${COLOR_DIM}(${tc_val}x timeout, model: ${model}, status: ${status})${RESET}"
        fi
    done

    # Latest supervisor analysis (show the most recent log if it exists)
    local latest_supervisor
    latest_supervisor=$(ls -t "${LOGS_DIR}"/supervisor-*.json 2>/dev/null | head -1 || true)
    if [[ -n "$latest_supervisor" ]] && [[ -f "$latest_supervisor" ]]; then
        local sup_diagnosis sup_pattern sup_recommendations
        sup_diagnosis=$(jq -r '.diagnosis // empty' "$latest_supervisor" 2>/dev/null)
        sup_pattern=$(jq -r '.pattern_detected.description // empty' "$latest_supervisor" 2>/dev/null)
        sup_recommendations=$(jq -r '[.recommendations // [] | .[]] | length' "$latest_supervisor" 2>/dev/null || echo "0")

        if [[ -n "$sup_diagnosis" ]] || [[ -n "$sup_pattern" ]]; then
            echo ""
            echo -e "${BOLD}Latest Supervisor Analysis:${RESET}"
            if [[ -n "$sup_diagnosis" ]]; then
                echo -e "  ${COLOR_DIM}Diagnosis:${RESET} ${sup_diagnosis}"
            fi
            if [[ -n "$sup_pattern" ]]; then
                local sup_root_cause
                sup_root_cause=$(jq -r '.pattern_detected.root_cause // "Unknown"' "$latest_supervisor" 2>/dev/null)
                echo -e "  ${COLOR_ERROR}Pattern:${RESET} ${sup_pattern}"
                echo -e "  ${COLOR_ERROR}Root cause:${RESET} ${sup_root_cause}"
            fi
            if [[ "$sup_recommendations" -gt 0 ]]; then
                echo -e "  ${COLOR_DIM}Suggestions:${RESET}"
                jq -r '.recommendations[]? | "    • \(.)"' "$latest_supervisor" 2>/dev/null
            fi
            echo -e "  ${COLOR_DIM}Full log: ${latest_supervisor}${RESET}"
        fi
    fi

    echo ""
}

# ── Coherence: cross-task consistency check ──────────────────

_print_coherence_delta() {
    local prev_file="$1"
    local new_json="$2"

    # Graceful no-op if prev file missing or unreadable
    [[ -f "$prev_file" ]] || return 0

    local prev_json
    prev_json=$(cat "$prev_file") || return 0

    # Validate both are JSON with critical_issues arrays
    local prev_issues new_issues
    prev_issues=$(echo "$prev_json" | jq -r '.critical_issues[]?' 2>/dev/null) || return 0
    new_issues=$(echo "$new_json" | jq -r '.critical_issues[]?' 2>/dev/null) || return 0

    # Handle empty arrays — if both empty, nothing to show
    [[ -z "$prev_issues" ]] && [[ -z "$new_issues" ]] && return 0
    # If no previous issues but new ones appeared, skip delta (first meaningful failure)
    [[ -z "$prev_issues" ]] && return 0

    # Compute sets: fixed, remaining, new
    local fixed=() remaining=() new_found=()

    # Check each previous issue
    while IFS= read -r issue; do
        [[ -z "$issue" ]] && continue
        if echo "$new_issues" | grep -qxF "$issue"; then
            remaining+=("$issue")
        else
            fixed+=("$issue")
        fi
    done <<< "$prev_issues"

    # Check for new issues (in new but not in prev)
    while IFS= read -r issue; do
        [[ -z "$issue" ]] && continue
        if ! echo "$prev_issues" | grep -qxF "$issue"; then
            new_found+=("$issue")
        fi
    done <<< "$new_issues"

    # Count transition
    local prev_count new_count
    prev_count=$(echo "$prev_json" | jq '.critical_issues | length' 2>/dev/null) || prev_count=0
    new_count=$(echo "$new_json" | jq '.critical_issues | length' 2>/dev/null) || new_count=0

    echo ""
    echo -e "  ${BOLD}Delta (vs. previous run):${RESET}"
    echo -e "  Critical issues: ${prev_count} ${SYM_ARROW} ${new_count}"

    for issue in "${fixed[@]}"; do
        echo -e "    ${COLOR_SUCCESS}${SYM_CHECK} Fixed:${RESET} ${issue}"
    done
    for issue in "${remaining[@]}"; do
        echo -e "    ${COLOR_WARN}${SYM_WARN} Remains:${RESET} ${issue}"
    done
    for issue in "${new_found[@]}"; do
        echo -e "    ${COLOR_ERROR}${SYM_CROSS} New:${RESET} ${issue}"
    done

    echo ""
    echo -e "  ${#fixed[@]} issue(s) fixed, ${#remaining[@]} remaining, ${#new_found[@]} new"

    # Celebratory message if all previous issues resolved and no new ones
    if [[ ${#remaining[@]} -eq 0 ]] && [[ ${#new_found[@]} -eq 0 ]]; then
        echo -e "  ${COLOR_SUCCESS}All previous issues resolved!${RESET}"
    fi

    echo ""
}

cmd_coherence() {
    _require_feature "$GLOBAL_FEATURE"
    log_header "Coherence Check"

    # Archive previous report for delta comparison
    local prev_report=""
    if [[ -f "${LOGS_DIR}/coherence.log" ]]; then
        cp "${LOGS_DIR}/coherence.log" "${LOGS_DIR}/coherence-prev.json"
        prev_report="${LOGS_DIR}/coherence-prev.json"
    fi

    local done_tasks
    done_tasks=$(task_list_by_status "done")

    if [[ -z "$done_tasks" ]]; then
        log_info "No completed tasks to check."
        return
    fi

    # Gather all diffs from completed tasks
    local all_diffs=""
    local task_count=0
    while IFS= read -r tid; do
        local task_json
        task_json=$(task_get "$tid")
        local title branch
        title=$(echo "$task_json" | jq -r '.title')
        branch=$(echo "$task_json" | jq -r '.branch')

        local diff=""
        if git_branch_exists "$branch"; then
            diff=$(git_diff_branch "$branch" 2>/dev/null || echo "No diff")
        fi

        all_diffs+="
--- TASK ${tid}: ${title} (branch: ${branch}) ---
\`\`\`diff
${diff}
\`\`\`

"
        ((task_count++))
    done <<< "$done_tasks"

    # Gather product spec
    local spec_content=""
    local spec_file
    spec_file=$(_get_spec_path)
    if [[ -n "$spec_file" ]] && [[ -f "$spec_file" ]]; then
        spec_content=$(cat "$spec_file")
    fi

    # Gather contract
    local contract_content=""
    if [[ -f "${CONTRACT_FILE}" ]]; then
        contract_content=$(cat "${CONTRACT_FILE}")
    fi

    local coherence_message="## Coherence Check: ${task_count} completed tasks

### All Task Diffs
${all_diffs}

### Product Specification
${spec_content}

### Data Model Contract
${contract_content}

Check that all these task implementations compose correctly. Focus on interfaces, schemas, naming consistency, duplicates, and missing connections."

    log_step "Sending ${task_count} task diffs to Coherence Checker..."
    echo ""

    local coherence_output
    if ! coherence_output=$(claude_run \
        "${AGENTS_DIR}/coherence-checker.md" \
        "$coherence_message" \
        "$MODEL_PLANNING" \
        "$AGENT_TOOLS_READONLY" \
        "Coherence"); then
        log_error "Coherence Checker agent failed — check Claude CLI connection"
        exit 1
    fi

    if [[ -z "$coherence_output" ]]; then
        log_error "Coherence Checker agent returned empty output"
        exit 1
    fi

    echo "$coherence_output"
    echo ""

    # Parse and save report
    local parsed_coherence
    parsed_coherence=$(parse_agent_json "$coherence_output") || parsed_coherence="$coherence_output"
    echo "$parsed_coherence" > "${LOGS_DIR}/coherence.log"
    log_success "Coherence report saved to ${LOGS_DIR}/coherence.log"

    if ! _require_json "Coherence Checker" "$parsed_coherence"; then
        log_error "Review raw output: ${LOGS_DIR}/coherence.log"
        exit 1
    fi

    # Show delta if a previous report exists
    if [[ -n "$prev_report" ]] && [[ -f "$prev_report" ]]; then
        _print_coherence_delta "$prev_report" "$parsed_coherence"
    fi

    local status
    status=$(echo "$parsed_coherence" | jq -r '.status // "unknown"')

    if [[ "$status" == "fail" ]]; then
        echo ""
        log_error "Coherence check FAILED — tasks have compatibility issues"
        local issue_count
        issue_count=$(echo "$parsed_coherence" | jq '.critical_issues | length')
        log_error "${issue_count} critical issue(s) found"
        echo ""
        echo -e "Fix issues before integrating. Options:"
        echo -e "  1. ${COLOR_STEP}speed retry --task-id ID --context \"...\"${RESET} to fix specific tasks"
        echo -e "  2. Review the coherence report and fix manually"
        exit 1
    elif [[ "$status" == "pass" ]]; then
        echo ""
        log_success "Coherence check PASSED — tasks are compatible"
        rm -f "${LOGS_DIR}/coherence-prev.json"
        echo -e "Next: ${COLOR_STEP}./speed/speed integrate${RESET}"
    else
        log_warn "Could not parse coherence status. Review the report manually."
    fi

    echo ""
}

cmd_integrate() {
    _require_feature "$GLOBAL_FEATURE"

    local skip_tests=false
    while [[ $# -gt 0 ]]; do
        case "$1" in
            --skip-tests) skip_tests=true; shift ;;
            *) log_error "Unknown option: $1"; exit 1 ;;
        esac
    done

    # ── Acquire exclusive lock ────────────────────────────────────
    speed_acquire_lock "integrate" || exit 1

    log_header "Integrating Completed Work"

    # Check for circular dependencies
    if ! task_topo_sort > /dev/null; then
        log_error "Cannot integrate: circular dependencies in task graph."
        exit 1
    fi

    local done_tasks
    done_tasks=$(task_list_by_status "done")

    if [[ -z "$done_tasks" ]]; then
        log_info "No completed tasks to integrate."
        return
    fi

    # Get branches in topological order
    local branches=()
    local ordered_tasks
    ordered_tasks=$(task_topo_sort)

    while IFS= read -r task_id; do
        local status
        status=$(jq -r '.status // "unknown"' "${TASKS_DIR}/${task_id}.json")
        if [[ "$status" == "done" ]]; then
            local branch
            branch=$(jq -r '.branch' "${TASKS_DIR}/${task_id}.json")
            if git_branch_exists "$branch"; then
                # Skip branches already merged (idempotent)
                if _git merge-base --is-ancestor "$branch" "$(git_main_branch)" 2>/dev/null; then
                    log_step "Branch ${branch} already merged — skipping"
                    continue
                fi
                branches+=("$branch")
            fi
        fi
    done <<< "$ordered_tasks"

    if [[ ${#branches[@]} -eq 0 ]]; then
        log_info "No branches to merge."
        return
    fi

    log_step "Merging ${#branches[@]} branches in dependency order..."
    echo ""

    # Build branch list for integrator
    local branch_list=""
    for b in "${branches[@]}"; do
        branch_list+="- ${b}"$'\n'
    done

    local integrate_branch
    integrate_branch=$(git_main_branch)

    local agent_message="## Integration Task

Merge the following branches into ${integrate_branch}, in the order listed (dependency order):

${branch_list}

### Working Directory
${PROJECT_ROOT}

### Instructions
1. For each branch, checkout ${integrate_branch}, then merge the branch with --no-ff
2. If there are merge conflicts, resolve them intelligently
3. After each merge, verify the code still works
4. Report results as JSON"

    log_step "Sending to Integrator agent..."

    local output
    if ! output=$(claude_run \
        "${AGENTS_DIR}/integrator.md" \
        "$agent_message" \
        "$MODEL_SUPPORT" \
        "$AGENT_TOOLS_FULL" \
        "Integrator"); then
        log_error "Integrator agent failed — check Claude CLI connection"
        exit 1
    fi

    if [[ -z "$output" ]]; then
        log_error "Integrator agent returned empty output"
        exit 1
    fi

    echo "$output"
    echo ""

    # Save integration log
    echo "$output" > "${LOGS_DIR}/integration.log"
    log_success "Integration log saved to ${LOGS_DIR}/integration.log"

    # ── Post-integration: regression tests ────────────────────────
    echo ""
    log_header "Post-Integration Verification"

    if [[ "$skip_tests" == true ]]; then
        log_info "Regression tests skipped (--skip-tests)"
    elif regression_run; then
        log_success "Regression tests passed"
    else
        log_error "Regression tests FAILED after integration"
        log_error "The merge may have introduced incompatibilities"
        echo ""
        echo -e "Options:"
        echo -e "  1. Check ${COLOR_STEP}${LOGS_DIR}/integration.log${RESET} for details"
        echo -e "  2. Use ${COLOR_STEP}git log --oneline${RESET} to review merge commits"
        echo -e "  3. Use ${COLOR_STEP}git reset --hard HEAD~N${RESET} to rollback (destructive)"
        echo ""
    fi

    # ── Post-integration: contract check ──────────────────────────
    if [[ -f "${CONTRACT_FILE}" ]]; then
        if contract_check; then
            log_success "Contract check passed — schema matches plan"
        else
            log_error "Contract check FAILED — built schema doesn't match the plan"
            log_error "This means the implementation doesn't support the product's core question"
            echo ""

            # Invoke supervisor for contract failure
            _invoke_supervisor "0" "contract"
        fi
    fi

    # ── Post-integration: Guardian vision check ──────────────────
    # Check: does the integrated result still align with the product vision?
    if [[ "${SKIP_GUARDIAN:-}" != "true" ]]; then
        echo ""
        log_header "Post-Integration Vision Check"

        # Gather the full integration diff
        local integration_diff=""
        for b in "${branches[@]}"; do
            integration_diff+="--- Branch: ${b} ---"$'\n'
            integration_diff+=$(git_diff_branch "$b" 2>/dev/null || echo "No diff")$'\n\n'
        done

        # Include the spec for context
        local spec_content=""
        local spec_file
        spec_file=$(_get_spec_path)
        if [[ -n "$spec_file" ]] && [[ -f "$spec_file" ]]; then
            spec_content="
### Feature Specification
$(cat "$spec_file")"
        fi

        local guardian_input="## Integrated Work: ${#branches[@]} branches merged

### Combined Diff
${integration_diff}
${spec_content}

This is a post-integration check. Evaluate whether the integrated result, taken as a whole, is consistent with the product vision."

        local grc=0
        local _guardian_out
        _guardian_out=$(_run_guardian "post-integration" "$guardian_input" "integration") || grc=$?
        if [[ $grc -eq 1 ]]; then
            echo ""
            log_error "Guardian REJECTED the integrated result — vision violation detected"
            log_error "Review the guardian report before shipping"
            echo -e "Report: ${COLOR_STEP}${LOGS_DIR}/guardian-post-integration-*.json${RESET}"
        elif [[ $grc -eq 3 ]]; then
            log_warn "Guardian returned unparseable output during post-integration check"
        fi
    fi

    echo ""
}

# ── Smart spec loader for review ──────────────────────────────────
# Instead of loading every spec file (which blows context/token budgets),
# load only specs that reference files or identifiers from the diff.
_load_relevant_specs() {
    local diff_text="$1"
    local primary_spec="$2"
    local specs_dir="${PROJECT_ROOT}/speed/specs"
    local result=""

    # Always include primary spec
    if [[ -n "$primary_spec" ]] && [[ -f "$primary_spec" ]]; then
        result="$primary_spec"
    fi

    [[ ! -d "$specs_dir" ]] && echo "$result" && return 0

    # Layer 1: file paths from diff
    local diff_paths
    diff_paths=$(echo "$diff_text" | grep -oE '(src|speed|lib)/[^ ]+' | sort -u 2>/dev/null || true)

    # Layer 2: identifiers (function names, class names) — 5+ chars, capped at 100
    local identifiers
    identifiers=$(echo "$diff_text" | grep -oE '[a-zA-Z_][a-zA-Z0-9_]{4,}' | sort -u | head -100 2>/dev/null || true)

    while IFS= read -r -d '' sf; do
        # Skip primary spec (already included)
        if [[ -n "$primary_spec" ]] && [[ "$(realpath "$sf" 2>/dev/null)" == "$(realpath "$primary_spec" 2>/dev/null)" ]]; then
            continue
        fi

        local matched=false

        # Layer 1: check if any diff file path appears in spec
        if [[ -n "$diff_paths" ]]; then
            while IFS= read -r dp; do
                [[ -z "$dp" ]] && continue
                if grep -q "$dp" "$sf" 2>/dev/null; then
                    matched=true
                    break
                fi
            done <<< "$diff_paths"
        fi

        # Layer 2: check if any identifier appears in spec (only if Layer 1 didn't match)
        if [[ "$matched" == "false" ]] && [[ -n "$identifiers" ]]; then
            while IFS= read -r id; do
                [[ -z "$id" ]] && continue
                if grep -q "$id" "$sf" 2>/dev/null; then
                    matched=true
                    break
                fi
            done <<< "$identifiers"
        fi

        [[ "$matched" == "true" ]] && result+=$'\n'"$sf"
    done < <(find "$specs_dir" -name '*.md' -type f -print0 | sort -z)

    echo "$result"
}

_print_review_nits() {
    local nits_json="$1"
    local count
    count=$(echo "$nits_json" | jq 'length' 2>/dev/null) || count=0

    [[ "$count" == "0" ]] || [[ -z "$count" ]] && return 0

    # Save to file
    echo "$nits_json" | jq '.' > "${LOGS_DIR}/review-nits.json"

    # Print summary
    echo ""
    echo -e "  ${BOLD}Review Nits (${count} items across approved tasks):${RESET}"
    echo ""

    echo "$nits_json" | jq -r '.[] | "\(.task_id): \(.severity) — \(.message // .description // "no message") (\(.file // "?"):\(.line // "?"))"' 2>/dev/null | while IFS= read -r line; do
        echo -e "    ${COLOR_WARN}${SYM_WARN}${RESET} ${line}"
    done

    echo ""
    echo -e "  ${COLOR_DIM}Full details: ${LOGS_DIR}/review-nits.json${RESET}"
}

cmd_review() {
    _require_feature "$GLOBAL_FEATURE"
    local task_id=""

    while [[ $# -gt 0 ]]; do
        case "$1" in
            --task-id) task_id="$2"; shift 2 ;;
            *) log_error "Unknown option: $1"; exit 1 ;;
        esac
    done

    log_header "Code Review"

    # If no task specified, review all done tasks
    local tasks_to_review
    if [[ -n "$task_id" ]]; then
        tasks_to_review="$task_id"
    else
        tasks_to_review=$(task_list_by_status "done")
    fi

    if [[ -z "$tasks_to_review" ]]; then
        log_info "No completed tasks to review."
        return
    fi

    # Filter out tasks that were already approved (prevent re-review)
    local filtered_tasks=""
    while IFS= read -r tid; do
        [[ -z "$tid" ]] && continue
        local rv
        rv=$(jq -r '.review_verdict // empty' "${TASKS_DIR}/${tid}.json" 2>/dev/null)
        if [[ "$rv" == "approve" ]]; then
            log_info "Task ${tid}: already approved, skipping"
        else
            filtered_tasks+="${tid}"$'\n'
        fi
    done <<< "$tasks_to_review"
    # Trim trailing newline
    filtered_tasks=$(echo "$filtered_tasks" | sed '/^$/d')

    if [[ -z "$filtered_tasks" ]]; then
        log_info "All completed tasks already reviewed."
        return
    fi
    tasks_to_review="$filtered_tasks"

    local all_nits="[]"

    while IFS= read -r tid; do
        local task_json
        task_json=$(task_get "$tid")
        local title branch criteria
        title=$(echo "$task_json" | jq -r '.title')
        branch=$(echo "$task_json" | jq -r '.branch')
        criteria=$(echo "$task_json" | jq -r '.acceptance_criteria')

        log_step "Reviewing task ${tid}: ${COLOR_STEP}${title}${RESET}"

        # Get the diff
        local diff=""
        if git_branch_exists "$branch"; then
            diff=$(git_diff_branch "$branch" 2>/dev/null || echo "No diff available")
        else
            log_warn "Branch ${branch} not found, skipping"
            continue
        fi

        # Truncate diff if too long
        local diff_lines
        diff_lines=$(echo "$diff" | wc -l | tr -d ' ')
        if [[ $diff_lines -gt $DIFF_HEAD_LINES ]]; then
            diff=$(echo "$diff" | head -n "$DIFF_HEAD_LINES")
            diff+=$'\n'"... (truncated at ${DIFF_HEAD_LINES} lines — full diff on branch ${branch})"
        fi

        # Gather relevant specs (smart loader — not all specs)
        local spec_context=""
        local spec_file
        spec_file=$(_get_spec_path)
        local relevant_specs
        relevant_specs=$(_load_relevant_specs "$diff" "$spec_file")
        while IFS= read -r sf; do
            [[ -z "$sf" ]] && continue
            local relpath="${sf#${PROJECT_ROOT}/}"
            if [[ -n "$spec_file" ]] && [[ "$(realpath "$sf" 2>/dev/null)" == "$(realpath "$spec_file" 2>/dev/null)" ]]; then
                spec_context+="
### Product Specification (SOURCE OF TRUTH — verify code satisfies this)
$(cat "$sf")"
            else
                spec_context+=$'\n\n'"--- RELATED SPEC: ${relpath} ---"$'\n'"$(cat "$sf")"
            fi
        done <<< "$relevant_specs"

        local agent_message="## Review Task ${tid}: ${title}

### Acceptance Criteria
${criteria}

### Git Diff (branch: ${branch})
\`\`\`diff
${diff}
\`\`\`
${spec_context}

### Instructions
1. Read the Product Specification FIRST — form your understanding of what this code should do
2. Check the diff against the spec — quote specific spec lines for each requirement you verify
3. Flag anything in the diff that doesn't trace to a spec requirement (potential over-engineering)
4. Then do standard code review (quality, conventions, security, tests)
Respond with your review as JSON."

        # Pace API call based on token budget
        local estimated_tokens
        estimated_tokens=$(_estimate_tokens "$agent_message")
        _pace_api_call "$estimated_tokens"

        local review_output
        if ! review_output=$(_call_with_retry claude_run \
            "${AGENTS_DIR}/reviewer.md" \
            "$agent_message" \
            "$MODEL_SUPPORT" \
            "$AGENT_TOOLS_READONLY" \
            "Reviewer"); then
            log_error "Reviewer agent failed for task ${tid} — check Claude CLI connection"
            continue
        fi

        # Track token usage after successful call
        _track_tokens "$estimated_tokens"

        if [[ -z "$review_output" ]]; then
            log_error "Reviewer agent returned empty output for task ${tid}"
            continue
        fi

        echo ""
        echo "$review_output"
        echo ""

        # Parse and save review
        local parsed_review
        parsed_review=$(parse_agent_json "$review_output") || parsed_review="$review_output"
        echo "$parsed_review" > "${LOGS_DIR}/review-${tid}.json"

        # Check verdict
        if ! _require_json "Reviewer" "$parsed_review"; then
            log_warn "Skipping review for task ${tid} — see ${LOGS_DIR}/review-${tid}.json"
            continue
        fi

        local verdict
        verdict=$(echo "$parsed_review" | jq -r '.verdict // "unknown"')
        if [[ "$verdict" == "request_changes" ]]; then
            log_warn "Task ${tid}: changes requested"
            # Atomic: status + review_feedback in one write
            task_request_changes "$tid" "$parsed_review"
        elif [[ "$verdict" == "approve" ]]; then
            log_success "Task ${tid}: approved by Reviewer"
            task_set_reviewed "$tid" "approve"

            # ── Collect nits from approved tasks ──────────────────
            local task_nits
            task_nits=$(echo "$parsed_review" | jq -c --arg tid "$tid" --arg title "$title" \
                '[.issues[]? | select(.severity == "nit" or .severity == "minor") | . + {task_id: $tid, task_title: $title}]' 2>/dev/null) || task_nits="[]"
            if [[ "$task_nits" != "[]" ]] && [[ -n "$task_nits" ]]; then
                all_nits=$(echo "$all_nits" "$task_nits" | jq -s 'add')
            fi

            # ── Post-Review Guardian Gate ──────────────────────────
            # Check: did the implementation drift from the vision?
            if [[ "${SKIP_GUARDIAN:-}" != "true" ]]; then
                local guardian_input="## Task ${tid}: ${title}

### Code Diff (branch: ${branch})
\`\`\`diff
${diff}
\`\`\`

### Task Acceptance Criteria
${criteria}"

                local grc=0
                local _guardian_out
                _guardian_out=$(_run_guardian "post-review" "$guardian_input" "task-${tid}") || grc=$?
                if [[ $grc -eq 1 ]]; then
                    log_error "Task ${tid}: Guardian REJECTED — vision violation in implementation"
                    local guardian_log
                    guardian_log=$(ls -t "${LOGS_DIR}"/guardian-post-review-*.json 2>/dev/null | head -1 || true)
                    # Atomic: status + review_feedback in one write
                    task_request_changes "$tid" "GUARDIAN REJECTED: $(cat "$guardian_log" 2>/dev/null | jq -r '.summary' 2>/dev/null || echo 'See guardian log')"
                    verdict="request_changes"
                elif [[ $grc -eq 3 ]]; then
                    log_warn "Task ${tid}: Guardian returned unparseable output — keeping approved status"
                fi
                # grc == 2 means flagged — warn but keep approved
            fi
        fi

    done <<< "$tasks_to_review"

    _print_review_nits "$all_nits"

    echo ""
}

cmd_retry() {
    _require_feature "$GLOBAL_FEATURE"
    local task_id=""
    local escalate=false
    local context=""

    while [[ $# -gt 0 ]]; do
        case "$1" in
            --task-id)  task_id="$2"; shift 2 ;;
            --escalate) escalate=true; shift ;;
            --context)  context="$2"; shift 2 ;;
            *) log_error "Unknown option: $1"; exit 1 ;;
        esac
    done

    if [[ -z "$task_id" ]]; then
        log_error "Required: --task-id ID"
        log_error "Retry requires targeting a specific task. Use ${COLOR_STEP}speed status${RESET} to see failed tasks."
        exit 1
    fi

    if [[ -z "$context" ]]; then
        # Show the failure details so the human can diagnose
        local task_json
        task_json=$(task_get "$task_id")
        local title error_msg status retry_count
        title=$(echo "$task_json" | jq -r '.title')
        error_msg=$(echo "$task_json" | jq -r '.error // "No error details"')
        status=$(echo "$task_json" | jq -r '.status')
        retry_count=$(echo "$task_json" | jq -r '.retry_count // 0')

        echo ""
        echo -e "${BOLD}Task ${task_id}:${RESET} ${title}"
        echo -e "${BOLD}Status:${RESET} ${status}"
        echo -e "${BOLD}Error:${RESET} ${error_msg}"
        echo -e "${BOLD}Previous retries:${RESET} ${retry_count}"

        # Show debugger analysis if available
        local debugger_log="${LOGS_DIR}/debugger-${task_id}.json"
        if [[ -f "$debugger_log" ]]; then
            echo ""
            echo -e "${BOLD}Debugger analysis:${RESET}"
            echo -e "  ${COLOR_DIM}$(cat "$debugger_log" | jq -r '.root_cause // .diagnosis // "See full log"' 2>/dev/null)${RESET}"
        fi

        echo ""
        log_error "Blind retries are not allowed. Diagnose the failure and provide guidance:"
        echo -e "  ${COLOR_STEP}speed retry --task-id ${task_id} --context \"what to do differently\"${RESET}"
        echo ""
        exit 1
    fi

    local task_json
    task_json=$(task_get "$task_id")
    local title current_model error_msg status
    title=$(echo "$task_json" | jq -r '.title')
    current_model=$(echo "$task_json" | jq -r '.agent_model')
    error_msg=$(echo "$task_json" | jq -r '.error // "No error details"')
    status=$(echo "$task_json" | jq -r '.status')

    if [[ "$status" != "failed" ]] && [[ "$status" != "blocked" ]]; then
        log_error "Task ${task_id} is '${status}', not failed or blocked. Nothing to retry."
        exit 1
    fi

    log_step "Retrying task ${task_id}: ${COLOR_STEP}${title}${RESET}"

    # Accumulate attempt history — append, never overwrite
    local prev_feedback
    prev_feedback=$(echo "$task_json" | jq -r '.review_feedback // ""')
    local retry_count
    retry_count=$(echo "$task_json" | jq -r '.retry_count // 0')
    local attempt_entry
    attempt_entry="--- Attempt $((retry_count + 1)) ---\nFailed with: ${error_msg}\nHuman guidance: ${context}"

    local accumulated_feedback
    if [[ -n "$prev_feedback" ]]; then
        accumulated_feedback="${prev_feedback}\n\n${attempt_entry}"
    else
        accumulated_feedback="$attempt_entry"
    fi
    task_update "$task_id" "review_feedback" "$(echo -e "$accumulated_feedback")"

    # Escalate model if requested
    if $escalate; then
        local new_model
        case "$current_model" in
            haiku)  new_model="sonnet" ;;
            sonnet) new_model="opus" ;;
            opus)   new_model="opus" ;;
        esac
        task_update "$task_id" "agent_model" "$new_model"
        log_info "Escalated model: ${current_model} → ${new_model}"
    fi

    # Clean up stale worktree if present
    git_remove_worktree "$task_id"

    # Atomic reset to pending (increments retry_count)
    task_reset_pending "$task_id"

    log_success "Task ${task_id} reset to pending (attempt $((retry_count + 2)))"

    echo ""
    echo -e "Run ${COLOR_STEP}./speed/speed run${RESET} to execute."
    echo ""
}

# ── Orphan agent detection and cleanup ───────────────────────
#
# After SIGKILL the orchestrator is gone but agent subshells keep running.
# Simply checking kill -0 $pid is unreliable because PIDs recycle.
# We use `ps -p $pid -o command=` to verify the process is actually a
# Claude CLI agent (contains "claude" in its command line), not an
# unrelated process that recycled the PID.

# Check if a PID is a live Claude agent (not a recycled PID).
# Returns 0 if the PID is alive AND looks like a claude process.
_is_claude_agent() {
    local pid="$1"

    # Not running at all — definitely not our agent
    kill -0 "$pid" 2>/dev/null || return 1

    # Running — verify it's actually a claude-related process
    local cmd_line
    cmd_line=$(ps -p "$pid" -o command= 2>/dev/null || echo "")
    if [[ -z "$cmd_line" ]]; then
        return 1  # Can't read process info — treat as not ours
    fi

    # Claude agents show up as "claude -p ..." or as bash subshells
    # that invoked claude. Check for claude or timeout (wrapper).
    if [[ "$cmd_line" == *claude* ]] || [[ "$cmd_line" == *timeout* ]]; then
        return 0
    fi

    # PID is alive but doesn't look like our agent — recycled PID
    return 1
}

# Kill a process tree: SIGTERM first, wait, then SIGKILL if still alive.
_kill_agent_tree() {
    local pid="$1"
    local task_label="${2:-unknown}"

    if ! kill -0 "$pid" 2>/dev/null; then
        return 0  # Already dead
    fi

    log_step "Terminating orphan agent for ${task_label} (PID ${pid})"

    # Kill the process group (negative PID) to catch child processes too.
    # Fall back to single-process kill if PGID kill fails (different session).
    kill -TERM -- -"$pid" 2>/dev/null || kill -TERM "$pid" 2>/dev/null || true

    # Wait up to 5 seconds for graceful shutdown
    local waited=0
    while kill -0 "$pid" 2>/dev/null && [[ $waited -lt 5 ]]; do
        sleep 1
        ((waited++))
    done

    # Force-kill if still alive
    if kill -0 "$pid" 2>/dev/null; then
        log_warn "Agent PID ${pid} didn't respond to SIGTERM — sending SIGKILL"
        kill -KILL -- -"$pid" 2>/dev/null || kill -KILL "$pid" 2>/dev/null || true
        sleep 1
    fi
}

# Kill all orphan agents for the current feature.
# Scans both running_dir PID files and task JSON agent_pid fields.
# Returns the count of orphans killed.
_kill_orphan_agents() {
    local killed=0
    local running_dir="${FEATURE_DIR}/running"
    local support_dir="${FEATURE_DIR}/support"

    # 1. Kill orphan developer agents tracked in running_dir
    if [[ -d "$running_dir" ]]; then
        for pid_file in "$running_dir"/*.pid; do
            [[ -f "$pid_file" ]] || continue
            local task_id pid
            task_id=$(basename "$pid_file" .pid)
            pid=$(cat "$pid_file")

            if _is_claude_agent "$pid"; then
                _kill_agent_tree "$pid" "task-${task_id}"
                ((killed++))
            fi
            rm -f "$pid_file"
            rm -f "${LOGS_DIR}/${task_id}.log.done"
        done
    fi

    # 2. Kill orphan support agents (debugger/supervisor) tracked in support_dir
    if [[ -d "$support_dir" ]]; then
        for pid_file in "$support_dir"/*.pid; do
            [[ -f "$pid_file" ]] || continue
            local support_name pid
            support_name=$(basename "$pid_file" .pid)
            pid=$(cat "$pid_file")

            if _is_claude_agent "$pid"; then
                _kill_agent_tree "$pid" "${support_name}"
                ((killed++))
            fi
            rm -f "$pid_file" "${support_dir}/${support_name}.task"
        done
    fi

    # 3. Cross-check: kill any agent_pid in task JSONs not caught above
    #    (covers case where running_dir was already deleted but task JSON retained the PID)
    for f in "${TASKS_DIR}"/*.json; do
        [[ -f "$f" ]] || continue
        local status agent_pid tid
        status=$(jq -r '.status // "unknown"' "$f")
        [[ "$status" == "running" ]] || continue

        tid=$(jq -r '.id' "$f")
        agent_pid=$(jq -r '.agent_pid // "null"' "$f")
        [[ "$agent_pid" == "null" ]] && continue

        if _is_claude_agent "$agent_pid"; then
            _kill_agent_tree "$agent_pid" "task-${tid}"
            ((killed++))
        fi
    done

    echo "$killed"
}

# ── Recover: fix stale state from crashed SPEED ──────────────

cmd_recover() {
    _require_feature "$GLOBAL_FEATURE"
    log_header "Recovering SPEED State"

    # Force-break any stale lock
    speed_force_break_lock

    local recovered=0

    # Kill any orphan agent processes first — before touching state
    local killed
    killed=$(_kill_orphan_agents)
    if [[ "$killed" -gt 0 ]]; then
        log_step "Killed ${killed} orphan agent process(es)"
        recovered=$((recovered + killed))
    fi

    # Reset "running" tasks to pending (agents are dead now)
    for f in "${TASKS_DIR}"/*.json; do
        [[ -f "$f" ]] || continue
        local status tid
        status=$(jq -r '.status' "$f")
        tid=$(jq -r '.id' "$f")

        if [[ "$status" == "running" ]]; then
            log_step "Resetting stale running task ${tid} to pending"
            task_reset_pending "$tid"
            git_remove_worktree "$tid"
            ((recovered++))
        fi
    done

    # Clean stale tracking directories
    rm -rf "${FEATURE_DIR}/running" "${FEATURE_DIR}/support"

    # Reset SPEED state
    jq '.status = "idle" | .agents = []' "$STATE_FILE" > "${STATE_FILE}.tmp" && mv "${STATE_FILE}.tmp" "$STATE_FILE"

    # Clean up orphaned worktrees
    git_cleanup_worktrees

    if [[ "$recovered" -gt 0 ]]; then
        log_success "Recovered ${recovered} stale item(s)"
    else
        log_info "No stale state found — SPEED is clean"
    fi

    echo ""
    task_print_summary
    echo ""
}

# ── Fix Nits ──────────────────────────────────────────────────────

cmd_fix_nits() {
    _require_feature "$GLOBAL_FEATURE"
    local filter_task_id=""

    while [[ $# -gt 0 ]]; do
        case "$1" in
            --task-id) filter_task_id="$2"; shift 2 ;;
            *) log_error "Unknown option: $1"; exit 1 ;;
        esac
    done

    log_header "Fix Nits"

    local nits_file="${LOGS_DIR}/review-nits.json"

    if [[ ! -f "$nits_file" ]]; then
        log_error "No nits found. Run 'speed review' first."
        exit 1
    fi

    local nits_json
    nits_json=$(cat "$nits_file")

    local nit_count
    nit_count=$(echo "$nits_json" | jq 'length' 2>/dev/null) || nit_count=0

    if [[ "$nit_count" == "0" ]] || [[ -z "$nit_count" ]]; then
        log_error "No nits found in ${nits_file}. Run 'speed review' first."
        exit 1
    fi

    # Filter by task ID if provided
    if [[ -n "$filter_task_id" ]]; then
        nits_json=$(echo "$nits_json" | jq --arg tid "$filter_task_id" '[.[] | select(.task_id == $tid)]')
        nit_count=$(echo "$nits_json" | jq 'length' 2>/dev/null) || nit_count=0
        if [[ "$nit_count" == "0" ]] || [[ -z "$nit_count" ]]; then
            log_error "No nits found for task ${filter_task_id}."
            exit 1
        fi
    fi

    # Compute next task ID (max existing + 1)
    local max_id=0
    for f in "${TASKS_DIR}"/*.json; do
        [[ -f "$f" ]] || continue
        local tid
        tid=$(jq -r '.id' "$f" 2>/dev/null) || continue
        if [[ "$tid" -gt "$max_id" ]] 2>/dev/null; then
            max_id="$tid"
        fi
    done
    local next_id=$((max_id + 1))

    # Collect unique original task IDs
    local source_task_ids
    source_task_ids=$(echo "$nits_json" | jq -r '[.[].task_id] | unique | join(", ")' 2>/dev/null)

    # Build numbered description from nits
    local description=""
    description+="Fix the following reviewer nits. Each fix is small and mechanical."
    description+="\n"

    local i=1
    while IFS= read -r nit_line; do
        [[ -z "$nit_line" ]] && continue
        local nit_task nit_severity nit_message nit_file nit_line_num nit_suggestion
        nit_task=$(echo "$nit_line" | jq -r '.task_id // "?"')
        nit_severity=$(echo "$nit_line" | jq -r '.severity // "nit"')
        nit_message=$(echo "$nit_line" | jq -r '.message // .description // "no message"')
        nit_file=$(echo "$nit_line" | jq -r '.file // "?"')
        nit_line_num=$(echo "$nit_line" | jq -r '.line // "?"')
        nit_suggestion=$(echo "$nit_line" | jq -r '.suggestion // empty')

        description+="\n${i}. **${nit_file}:${nit_line_num}** (${nit_severity}, from task ${nit_task})"
        description+="\n   Issue: ${nit_message}"
        if [[ -n "$nit_suggestion" ]]; then
            description+="\n   Fix: ${nit_suggestion}"
        fi

        i=$((i + 1))
    done < <(echo "$nits_json" | jq -c '.[]')

    description+="\n\nApply each fix. If a suggestion is wrong or not applicable, add a code comment explaining why it was skipped."

    # Build acceptance criteria
    local criteria="- Each nit is fixed or has a comment explaining why not applicable\n- No new lint/typecheck/test failures\n- All quality gates pass"

    # Build depends_on from unique original task IDs
    local depends_on
    depends_on=$(echo "$nits_json" | jq -c '[.[].task_id] | unique')

    # Build files_touched from unique file paths
    local files_touched
    files_touched=$(echo "$nits_json" | jq -c '[.[].file // empty] | unique | map(select(. != "?"))')

    # Create the task
    local title="Fix review nits from tasks ${source_task_ids}"

    task_create "$next_id" "$title" "$(echo -e "$description")" "$(echo -e "$criteria")" "$depends_on" "$MODEL_SUPPORT"
    task_update_raw "$next_id" "files_touched" "$files_touched"

    echo ""
    log_success "Created task ${next_id}: ${title}"
    log_step "${nit_count} nit(s) from task(s) ${source_task_ids}"
    echo ""
    echo -e "  ${COLOR_DIM}Next: ${COLOR_STEP}speed run${COLOR_DIM} && ${COLOR_STEP}speed review${RESET}"
    echo ""
}

# ── Clean ─────────────────────────────────────────────────────────

cmd_clean() {
    local what="${1:-logs}"

    case "$what" in
        logs)
            # If a feature is specified or active, clean that feature's logs
            if feature_resolve "$GLOBAL_FEATURE" &>/dev/null; then
                _require_feature "$GLOBAL_FEATURE"
                local file_count size_before
                file_count=$(ls -1 "$LOGS_DIR" 2>/dev/null | wc -l | tr -d ' ')
                size_before=$(du -sh "$LOGS_DIR" 2>/dev/null | cut -f1)
                rm -rf "$LOGS_DIR"
                mkdir -p "$LOGS_DIR"
                log_success "Cleaned ${file_count} log files (${size_before}) for feature ${FEATURE_NAME}"
            else
                # Clean logs across all features
                local total_cleaned=0
                for feat_dir in "${FEATURES_DIR}"/*/logs; do
                    [[ -d "$feat_dir" ]] || continue
                    local fc
                    fc=$(ls -1 "$feat_dir" 2>/dev/null | wc -l | tr -d ' ')
                    total_cleaned=$((total_cleaned + fc))
                    rm -rf "$feat_dir"
                    mkdir -p "$feat_dir"
                done
                # Also clean top-level logs
                if [[ -d "${STATE_DIR}/logs" ]]; then
                    local fc
                    fc=$(ls -1 "${STATE_DIR}/logs" 2>/dev/null | wc -l | tr -d ' ')
                    total_cleaned=$((total_cleaned + fc))
                    rm -rf "${STATE_DIR}/logs"
                    mkdir -p "${STATE_DIR}/logs"
                fi
                log_success "Cleaned ${total_cleaned} log files across all features"
            fi
            ;;

        feature)
            local feat_name="${2:-}"
            if [[ -z "$feat_name" ]]; then
                log_error "Usage: speed clean feature <name>"
                echo ""
                echo "Available features:"
                feature_list | while IFS= read -r f; do echo "  - $f"; done
                exit 1
            fi
            local feat_dir="${FEATURES_DIR}/${feat_name}"
            if [[ ! -d "$feat_dir" ]]; then
                log_error "Feature '${feat_name}' not found"
                exit 1
            fi
            # Clean worktrees for this feature
            local wt_dir="${STATE_DIR}/worktrees/${feat_name}"
            if [[ -d "$wt_dir" ]]; then
                for wt in "$wt_dir"/task-*; do
                    [[ -d "$wt" ]] || continue
                    git -C "$PROJECT_ROOT" worktree remove --force "$wt" 2>/dev/null || rm -rf "$wt"
                done
                git -C "$PROJECT_ROOT" worktree prune 2>/dev/null || true
            fi
            local size_before
            size_before=$(du -sh "$feat_dir" 2>/dev/null | cut -f1)
            rm -rf "$feat_dir" "$wt_dir"
            # Clear active feature if it was the one we deleted
            if [[ "$(feature_get_active)" == "$feat_name" ]]; then
                rm -f "${STATE_DIR}/active_feature"
            fi
            log_success "Cleaned feature '${feat_name}' (${size_before})"
            ;;

        all)
            if [[ ! -d "$STATE_DIR" ]]; then
                log_info "No .speed directory — nothing to clean"
                return 0
            fi

            # Clean all worktrees (iterate all feature worktree dirs)
            if [[ -d "${STATE_DIR}/worktrees" ]]; then
                for wt_dir in "${STATE_DIR}"/worktrees/*/task-* "${STATE_DIR}"/worktrees/task-*; do
                    [[ -d "$wt_dir" ]] || continue
                    git -C "$PROJECT_ROOT" worktree remove --force "$wt_dir" 2>/dev/null || rm -rf "$wt_dir"
                done
                git -C "$PROJECT_ROOT" worktree prune 2>/dev/null || true
            fi

            local size_before
            size_before=$(du -sh "$STATE_DIR" 2>/dev/null | cut -f1)

            rm -rf "$STATE_DIR"
            log_success "Cleaned entire .speed/ directory (${size_before})"
            ;;

        *)
            echo -e "Usage: ${COLOR_STEP}./speed/speed clean${RESET} [logs|feature <name>|all]"
            echo ""
            echo -e "  ${COLOR_STEP}logs${RESET}               Remove log files (active feature or all)"
            echo -e "  ${COLOR_STEP}feature <name>${RESET}      Remove a specific feature's state and worktrees"
            echo -e "  ${COLOR_STEP}all${RESET}                Remove entire .speed/ directory"
            ;;
    esac
}

# ── New ───────────────────────────────────────────────────────────

cmd_new() {
    local subcommand="${1:-}"
    local name="${2:-}"

    log_header "Creating new ${subcommand:-spec} spec"

    # Validate subcommand
    case "$subcommand" in
        prd|rfc|design|defect) ;;
        *)
            log_error "Invalid subcommand: '${subcommand}'"
            echo "" >&2
            echo -e "  Valid types: ${COLOR_STEP}prd${RESET}  ${COLOR_STEP}rfc${RESET}  ${COLOR_STEP}design${RESET}  ${COLOR_STEP}defect${RESET}" >&2
            echo "" >&2
            exit "$EXIT_CONFIG_ERROR"
            ;;
    esac

    # Validate name (required)
    if [[ -z "$name" ]]; then
        log_error "Usage: ./speed/speed new <type> <name>"
        echo "" >&2
        echo -e "  Example: ${COLOR_STEP}./speed/speed new ${subcommand} my-feature${RESET}" >&2
        echo "" >&2
        exit "$EXIT_CONFIG_ERROR"
    fi

    # Validate name format: lowercase alphanumeric + hyphens, no leading/trailing hyphens
    if ! echo "$name" | grep -qE '^[a-z0-9]([a-z0-9-]*[a-z0-9])?$'; then
        log_error "Invalid name: '${name}'"
        echo "" >&2
        echo -e "  Name must be lowercase alphanumeric with hyphens (no leading/trailing hyphens)" >&2
        echo -e "  Example: ${COLOR_STEP}my-feature${RESET}, ${COLOR_STEP}fix-login-bug${RESET}, ${COLOR_STEP}auth${RESET}" >&2
        echo "" >&2
        exit "$EXIT_CONFIG_ERROR"
    fi

    # Map subcommand to template and output directory
    local template output_dir
    case "$subcommand" in
        prd)    template="${TEMPLATES_DIR}/prd.md";    output_dir="specs/product" ;;
        rfc)    template="${TEMPLATES_DIR}/rfc.md";    output_dir="specs/tech" ;;
        design) template="${TEMPLATES_DIR}/design.md"; output_dir="specs/design" ;;
        defect) template="${TEMPLATES_DIR}/defect.md"; output_dir="specs/defects" ;;
    esac

    # Check template exists
    if [[ ! -f "$template" ]]; then
        log_error "Template not found: ${template}"
        echo "" >&2
        echo -e "  This may indicate an incomplete SPEED installation." >&2
        echo -e "  Expected template at: ${COLOR_STEP}${template}${RESET}" >&2
        echo "" >&2
        exit "$EXIT_CONFIG_ERROR"
    fi

    local output="${PROJECT_ROOT}/${output_dir}/${name}.md"

    # Check output file does not already exist
    if [[ -f "$output" ]]; then
        log_error "File already exists: ${output}"
        echo "" >&2
        echo -e "  To avoid overwriting, the existing file was left unchanged." >&2
        echo "" >&2
        exit "$EXIT_CONFIG_ERROR"
    fi

    # Create output directory
    mkdir -p "${PROJECT_ROOT}/${output_dir}"

    # Humanize name: hyphens → spaces, title case
    local humanized
    humanized=$(echo "$name" | tr '-' ' ' | awk '{for(i=1;i<=NF;i++) $i=toupper(substr($i,1,1)) substr($i,2)} 1')

    # Copy template with placeholder substitution
    sed -e "s/{Feature Name}/${humanized}/g" \
        -e "s/{name}/${name}/g" \
        -e "s|{product-spec}|specs/product/${name}.md|g" \
        "$template" > "$output"

    log_success "Created ${output_dir}/${name}.md"

    # Open in editor if set
    if [[ -n "${EDITOR:-}" ]]; then
        exec "$EDITOR" "$output"
    fi
}

# ── Main ─────────────────────────────────────────────────────────

main() {
    local command="${1:-help}"
    shift || true

    # ── Extract global flags before dispatching ─────────────────
    GLOBAL_FEATURE=""
    local args=()
    while [[ $# -gt 0 ]]; do
        case "$1" in
            --feature|-f)  GLOBAL_FEATURE="$2"; shift 2 ;;
            --quiet)       VERBOSITY=0; shift ;;
            --verbose)     VERBOSITY=2; shift ;;
            --debug)       VERBOSITY=3; shift ;;
            --json)        JSON_OUTPUT=true; VERBOSITY=0; shift ;;
            *) args+=("$1"); shift ;;
        esac
    done
    set -- "${args[@]+"${args[@]}"}"

    case "$command" in
        init)      cmd_init "$@" ;;
        validate)  cmd_validate "$@" ;;
        plan)      cmd_plan "$@" ;;
        verify)    cmd_verify "$@" ;;
        run)       cmd_run "$@" ;;
        status)    cmd_status "$@" ;;
        coherence) cmd_coherence "$@" ;;
        integrate) cmd_integrate "$@" ;;
        review)    cmd_review "$@" ;;
        fix-nits)  cmd_fix_nits "$@" ;;
        retry)     cmd_retry "$@" ;;
        recover)   cmd_recover "$@" ;;
        new)       cmd_new "$@" ;;
        guardian)   cmd_guardian "$@" ;;
        gates)     cmd_gates "$@" ;;
        clean)     cmd_clean "$@" ;;
        help|--help|-h) speed_help ;;
        *)
            log_error "Unknown command: ${command}"
            speed_help
            exit 1
            ;;
    esac
}

main "$@"
